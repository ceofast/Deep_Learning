{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNd1qd2k613gc5aKI8sf5i7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ceofast/Deep_Learning/blob/main/Introduction_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI90201 Neural Networks"
      ],
      "metadata": {
        "id": "t6sxyY0mc4lT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = fetch_openml('mnist_784', version = 1, return_X_y = True, as_frame = False)\n",
        "\n",
        "X = X / 255.0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.7)"
      ],
      "metadata": {
        "id": "OwRh41UBdCKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame(X)\n",
        "\n",
        "data.insert(784, 'label', y)\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "cJD_9is3duq7",
        "outputId": "c7ec36dd-c262-42b3-9b6d-c1a93ec5f19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0    1    2    3    4    5    6    7    8    9  ...  775  776  777  778  \\\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "\n",
              "   779  780  781  782  783  label  \n",
              "0  0.0  0.0  0.0  0.0  0.0      5  \n",
              "1  0.0  0.0  0.0  0.0  0.0      0  \n",
              "2  0.0  0.0  0.0  0.0  0.0      4  \n",
              "3  0.0  0.0  0.0  0.0  0.0      1  \n",
              "4  0.0  0.0  0.0  0.0  0.0      9  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01a1acf0-ce07-4240-b4e5-eee24217c2d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01a1acf0-ce07-4240-b4e5-eee24217c2d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01a1acf0-ce07-4240-b4e5-eee24217c2d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01a1acf0-ce07-4240-b4e5-eee24217c2d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(5):\n",
        "  plt.imshow(X[i].reshape((28, 28)), cmap = 'gray')\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Gh19z_-ld7_-",
        "outputId": "6a21894d-ad0f-4c76-9012-4e1a0b99e228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes = 1, activation = 'logistic')\n",
        "\n",
        "mlp1 = MLPClassifier(hidden_layer_sizes = 100, activation = 'logistic')\n",
        "\n",
        "mlp2 = MLPClassifier(hidden_layer_sizes = 1000, activation = 'logistic')"
      ],
      "metadata": {
        "id": "yvy1FibueUhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "mlp1.fit(X_train, y_train)\n",
        "\n",
        "mlp2.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUuX0xiMe6nZ",
        "outputId": "03796d47-27db-406a-f4b0-e684937c7390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', hidden_layer_sizes=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_NN = mlp.predict(X_test)\n",
        "predictions_NN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02IG6mVnfRuC",
        "outputId": "2c35a7e8-a1e6-44e2-e130-bb39bdec8403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['6', '4', '1', ..., '3', '1', '4'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_NN1 = mlp1.predict(X_test)\n",
        "predictions_NN1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF_HO7tujOp4",
        "outputId": "56835c6c-9ca9-4032-cd65-5da99e7df00e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '4', '1', ..., '8', '3', '2'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_NN2 = mlp2.predict(X_test)\n",
        "predictions_NN2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9jsud65jWDs",
        "outputId": "5084f97e-dee3-466e-9d5e-69591d5d70b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '4', '1', ..., '8', '3', '9'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Actual Value: {y_test[1]}')\n",
        "print(f'Predicted Value For 1 Hidden Layer: {predictions_NN[1]}')\n",
        "print(f'Predicted Value For 100 Hidden Layer: {predictions_NN1[1]}')\n",
        "print(f'Predicted Value For 1000 Hidden Layer: {predictions_NN2[1]}')\n",
        "\n",
        "plt.imshow(X_test[1].reshape((28,28)), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "s8iCGGVAjc8s",
        "outputId": "c1f3a8b7-2216-4c7d-9a4f-7114231cedbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual Value: 4\n",
            "Predicted Value For 1 Hidden Layer: 4\n",
            "Predicted Value For 100 Hidden Layer: 4\n",
            "Predicted Value For 1000 Hidden Layer: 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_test, predictions_NN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4shA1bPkQKe",
        "outputId": "87ab9b42-69b1-4291-dae9-a7207973ab29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 106, 1060,    0,  164,   16,    0, 3548,   17,    0,    0],\n",
              "       [  59, 4731,    0,  496,   45,    0,  177,   36,    0,    0],\n",
              "       [ 112, 1900,    0,  633,   51,    0, 2167,   33,    0,    0],\n",
              "       [  10,  740,    0, 2994,  636,    0,  175,  431,    0,    0],\n",
              "       [   0,   97,    0,  686, 2092,    0,   19, 1874,    0,    0],\n",
              "       [  16,  768,    0, 2491,  551,    0,  119,  439,    0,    0],\n",
              "       [  46,  505,    0,   88,   10,    0, 4130,    1,    0,    0],\n",
              "       [   0,   51,    0,  114,  131,    0,    4, 4772,    0,    0],\n",
              "       [   5,  869,    0, 2872,  545,    0,   49,  417,    0,    0],\n",
              "       [   0,   33,    0,  160,  240,    0,    9, 4460,    0,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, predictions_NN1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqGV8SK7kdiV",
        "outputId": "438aab37-5103-4d93-b07c-a131ab33e3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4794,    2,   13,    7,   10,   15,   36,    7,   21,    6],\n",
              "       [   2, 5475,   22,   11,    4,    3,    3,    8,    8,    8],\n",
              "       [  15,    8, 4721,   22,   37,    2,   17,   34,   34,    6],\n",
              "       [   6,   11,   69, 4711,    3,   86,    5,   27,   47,   21],\n",
              "       [   3,   11,   15,    4, 4610,    4,   27,   14,    7,   73],\n",
              "       [  13,    7,   16,   62,   16, 4169,   42,    8,   27,   24],\n",
              "       [  17,   11,   11,    3,   21,   27, 4673,    4,   13,    0],\n",
              "       [   6,   17,   42,   13,   36,    3,    0, 4911,    5,   39],\n",
              "       [  25,   38,   33,   37,   16,   45,   21,    7, 4509,   26],\n",
              "       [  14,    9,   10,   35,   92,   24,    2,   67,   18, 4631]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, predictions_NN2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9yX3owSkiYm",
        "outputId": "ed93100e-b818-42db-ee39-73872011b63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4823,    2,   13,    6,    5,   13,   21,    3,   17,    8],\n",
              "       [   1, 5476,   27,    8,    5,    1,    5,    5,    7,    9],\n",
              "       [  17,    8, 4760,   17,   28,    2,   14,   25,   20,    5],\n",
              "       [   6,   11,   65, 4751,    5,   60,    3,   15,   49,   21],\n",
              "       [   5,   14,   15,    2, 4612,    3,   20,    9,    7,   81],\n",
              "       [  16,    7,   10,   39,    8, 4228,   29,    7,   22,   18],\n",
              "       [  20,   11,   20,    4,   16,   19, 4671,    6,   13,    0],\n",
              "       [   1,   21,   52,   18,   37,    5,    0, 4877,   10,   51],\n",
              "       [  18,   31,   23,   32,   14,   29,   19,    1, 4564,   26],\n",
              "       [  20,   13,    1,   27,   56,   26,    3,   44,   20, 4692]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, predictions_NN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWPYwiIbkkN0",
        "outputId": "2f2cca2f-acc9-417c-c62c-9b441f0ce895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.02      0.04      4911\n",
            "           1       0.44      0.85      0.58      5544\n",
            "           2       0.00      0.00      0.00      4896\n",
            "           3       0.28      0.60      0.38      4986\n",
            "           4       0.48      0.44      0.46      4768\n",
            "           5       0.00      0.00      0.00      4384\n",
            "           6       0.40      0.86      0.54      4780\n",
            "           7       0.38      0.94      0.54      5072\n",
            "           8       0.00      0.00      0.00      4757\n",
            "           9       0.00      0.00      0.00      4902\n",
            "\n",
            "    accuracy                           0.38     49000\n",
            "   macro avg       0.23      0.37      0.26     49000\n",
            "weighted avg       0.23      0.38      0.26     49000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, predictions_NN1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDg5Zh_skwi4",
        "outputId": "bc35e9b3-b149-4c6e-cdbc-dc53269190a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      4911\n",
            "           1       0.98      0.99      0.98      5544\n",
            "           2       0.95      0.96      0.96      4896\n",
            "           3       0.96      0.94      0.95      4986\n",
            "           4       0.95      0.97      0.96      4768\n",
            "           5       0.95      0.95      0.95      4384\n",
            "           6       0.97      0.98      0.97      4780\n",
            "           7       0.97      0.97      0.97      5072\n",
            "           8       0.96      0.95      0.95      4757\n",
            "           9       0.96      0.94      0.95      4902\n",
            "\n",
            "    accuracy                           0.96     49000\n",
            "   macro avg       0.96      0.96      0.96     49000\n",
            "weighted avg       0.96      0.96      0.96     49000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, predictions_NN2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3cd3Axdk5xK",
        "outputId": "d7975b85-1cbf-4130-cdee-5462707585e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      4911\n",
            "           1       0.98      0.99      0.98      5544\n",
            "           2       0.95      0.97      0.96      4896\n",
            "           3       0.97      0.95      0.96      4986\n",
            "           4       0.96      0.97      0.97      4768\n",
            "           5       0.96      0.96      0.96      4384\n",
            "           6       0.98      0.98      0.98      4780\n",
            "           7       0.98      0.96      0.97      5072\n",
            "           8       0.97      0.96      0.96      4757\n",
            "           9       0.96      0.96      0.96      4902\n",
            "\n",
            "    accuracy                           0.97     49000\n",
            "   macro avg       0.97      0.97      0.97     49000\n",
            "weighted avg       0.97      0.97      0.97     49000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI9022 Training Neural Networks\n",
        "\n",
        "There are two types of parameters in any deep learning model.\n",
        "\n",
        "* Hyperparameters\n",
        "* Learnable \n",
        "\n",
        "Hyperparameters are the parameters that we humans can adjust. Examples of Hyperparameters can be the learning rate, number of hidden layers or number of nodes."
      ],
      "metadata": {
        "id": "eccSHDmlls9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI9032 Build an Artificial Neural Network\n",
        "\n",
        "#### Classifying Dates\n",
        "\n",
        "In tihs project, we will build a neural network to classify dates. For this we will use the \"Date Fruit Dataset\" available on Kaggle. This dataset includes samples of dates that can be classified into 7 classes according to their types."
      ],
      "metadata": {
        "id": "KeFWdRRQw5_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the required libraries\n",
        "\n",
        "We'll start with importing required libraries.\n",
        "Use the keywords \"import\" and \"from\"."
      ],
      "metadata": {
        "id": "D3SUb7zqxi0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Pandas and Matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import Label Encoder and train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, minmax_scale\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "jMsaC7jNlxYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset\n",
        "\n",
        "Let's load the .xlsx file.\n",
        "\n",
        "Use the read_excel() function of the Pandas library."
      ],
      "metadata": {
        "id": "AUcp8xEQyOCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the \"date_fruit.xlsx\" file\n",
        "\n",
        "data = pd.read_excel('/content/date_fruit.xlsx')"
      ],
      "metadata": {
        "id": "nJJFGNenyM5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we take a look at the dataset.\n",
        "\n",
        "Use the data.head() function.\n",
        "\n",
        "Use .shape attribute and .uniqe() methods.\n",
        "\n"
      ],
      "metadata": {
        "id": "kGDApW_9yjzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the head() function to display the first 5 rows of the data.\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "bhQPZVMZyvLt",
        "outputId": "b308beca-4b37-46b1-8f77-f78fd136dd97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n",
              "0  422163   2378.908    837.8484    645.6693        0.6373  733.1539   \n",
              "1  338136   2085.144    723.8198    595.2073        0.5690  656.1464   \n",
              "2  526843   2647.394    940.7379    715.3638        0.6494  819.0222   \n",
              "3  416063   2351.210    827.9804    645.2988        0.6266  727.8378   \n",
              "4  347562   2160.354    763.9877    582.8359        0.6465  665.2291   \n",
              "\n",
              "   SOLIDITY  CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  KurtosisRR  KurtosisRG  \\\n",
              "0    0.9947       424428  0.7831        1.2976  ...      3.2370      2.9574   \n",
              "1    0.9974       339014  0.7795        1.2161  ...      2.6228      2.6350   \n",
              "2    0.9962       528876  0.7657        1.3150  ...      3.7516      3.8611   \n",
              "3    0.9948       418255  0.7759        1.2831  ...      5.0401      8.6136   \n",
              "4    0.9908       350797  0.7569        1.3108  ...      2.7016      2.9761   \n",
              "\n",
              "   KurtosisRB    EntropyRR    EntropyRG    EntropyRB  ALLdaub4RR  ALLdaub4RG  \\\n",
              "0      4.2287 -59191263232 -50714214400 -39922372608     58.7255     54.9554   \n",
              "1      3.1704 -34233065472 -37462601728 -31477794816     50.0259     52.8168   \n",
              "2      4.7192 -93948354560 -74738221056 -60311207936     65.4772     59.2860   \n",
              "3      8.2618 -32074307584 -32060925952 -29575010304     43.3900     44.1259   \n",
              "4      4.4146 -39980974080 -35980042240 -25593278464     52.7743     50.9080   \n",
              "\n",
              "   ALLdaub4RB  Class  \n",
              "0     47.8400  BERHI  \n",
              "1     47.8315  BERHI  \n",
              "2     51.9378  BERHI  \n",
              "3     41.1882  BERHI  \n",
              "4     42.6666  BERHI  \n",
              "\n",
              "[5 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-863c912e-4ab4-423b-9dc2-add80f2c228a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AREA</th>\n",
              "      <th>PERIMETER</th>\n",
              "      <th>MAJOR_AXIS</th>\n",
              "      <th>MINOR_AXIS</th>\n",
              "      <th>ECCENTRICITY</th>\n",
              "      <th>EQDIASQ</th>\n",
              "      <th>SOLIDITY</th>\n",
              "      <th>CONVEX_AREA</th>\n",
              "      <th>EXTENT</th>\n",
              "      <th>ASPECT_RATIO</th>\n",
              "      <th>...</th>\n",
              "      <th>KurtosisRR</th>\n",
              "      <th>KurtosisRG</th>\n",
              "      <th>KurtosisRB</th>\n",
              "      <th>EntropyRR</th>\n",
              "      <th>EntropyRG</th>\n",
              "      <th>EntropyRB</th>\n",
              "      <th>ALLdaub4RR</th>\n",
              "      <th>ALLdaub4RG</th>\n",
              "      <th>ALLdaub4RB</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>422163</td>\n",
              "      <td>2378.908</td>\n",
              "      <td>837.8484</td>\n",
              "      <td>645.6693</td>\n",
              "      <td>0.6373</td>\n",
              "      <td>733.1539</td>\n",
              "      <td>0.9947</td>\n",
              "      <td>424428</td>\n",
              "      <td>0.7831</td>\n",
              "      <td>1.2976</td>\n",
              "      <td>...</td>\n",
              "      <td>3.2370</td>\n",
              "      <td>2.9574</td>\n",
              "      <td>4.2287</td>\n",
              "      <td>-59191263232</td>\n",
              "      <td>-50714214400</td>\n",
              "      <td>-39922372608</td>\n",
              "      <td>58.7255</td>\n",
              "      <td>54.9554</td>\n",
              "      <td>47.8400</td>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>338136</td>\n",
              "      <td>2085.144</td>\n",
              "      <td>723.8198</td>\n",
              "      <td>595.2073</td>\n",
              "      <td>0.5690</td>\n",
              "      <td>656.1464</td>\n",
              "      <td>0.9974</td>\n",
              "      <td>339014</td>\n",
              "      <td>0.7795</td>\n",
              "      <td>1.2161</td>\n",
              "      <td>...</td>\n",
              "      <td>2.6228</td>\n",
              "      <td>2.6350</td>\n",
              "      <td>3.1704</td>\n",
              "      <td>-34233065472</td>\n",
              "      <td>-37462601728</td>\n",
              "      <td>-31477794816</td>\n",
              "      <td>50.0259</td>\n",
              "      <td>52.8168</td>\n",
              "      <td>47.8315</td>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>526843</td>\n",
              "      <td>2647.394</td>\n",
              "      <td>940.7379</td>\n",
              "      <td>715.3638</td>\n",
              "      <td>0.6494</td>\n",
              "      <td>819.0222</td>\n",
              "      <td>0.9962</td>\n",
              "      <td>528876</td>\n",
              "      <td>0.7657</td>\n",
              "      <td>1.3150</td>\n",
              "      <td>...</td>\n",
              "      <td>3.7516</td>\n",
              "      <td>3.8611</td>\n",
              "      <td>4.7192</td>\n",
              "      <td>-93948354560</td>\n",
              "      <td>-74738221056</td>\n",
              "      <td>-60311207936</td>\n",
              "      <td>65.4772</td>\n",
              "      <td>59.2860</td>\n",
              "      <td>51.9378</td>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>416063</td>\n",
              "      <td>2351.210</td>\n",
              "      <td>827.9804</td>\n",
              "      <td>645.2988</td>\n",
              "      <td>0.6266</td>\n",
              "      <td>727.8378</td>\n",
              "      <td>0.9948</td>\n",
              "      <td>418255</td>\n",
              "      <td>0.7759</td>\n",
              "      <td>1.2831</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0401</td>\n",
              "      <td>8.6136</td>\n",
              "      <td>8.2618</td>\n",
              "      <td>-32074307584</td>\n",
              "      <td>-32060925952</td>\n",
              "      <td>-29575010304</td>\n",
              "      <td>43.3900</td>\n",
              "      <td>44.1259</td>\n",
              "      <td>41.1882</td>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>347562</td>\n",
              "      <td>2160.354</td>\n",
              "      <td>763.9877</td>\n",
              "      <td>582.8359</td>\n",
              "      <td>0.6465</td>\n",
              "      <td>665.2291</td>\n",
              "      <td>0.9908</td>\n",
              "      <td>350797</td>\n",
              "      <td>0.7569</td>\n",
              "      <td>1.3108</td>\n",
              "      <td>...</td>\n",
              "      <td>2.7016</td>\n",
              "      <td>2.9761</td>\n",
              "      <td>4.4146</td>\n",
              "      <td>-39980974080</td>\n",
              "      <td>-35980042240</td>\n",
              "      <td>-25593278464</td>\n",
              "      <td>52.7743</td>\n",
              "      <td>50.9080</td>\n",
              "      <td>42.6666</td>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 35 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-863c912e-4ab4-423b-9dc2-add80f2c228a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-863c912e-4ab4-423b-9dc2-add80f2c228a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-863c912e-4ab4-423b-9dc2-add80f2c228a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape pof data and classes\n",
        "\n",
        "print(data.shape)\n",
        "\n",
        "print(data['Class'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlK0NeZ-y3Ie",
        "outputId": "87c68e93-bd17-4745-c3af-3d7cd03ba70c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(898, 35)\n",
            "['BERHI' 'DEGLET' 'DOKOL' 'IRAQI' 'ROTANA' 'SAFAVI' 'SOGAY']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing\n",
        "\n",
        "Now that we have a better understanding of our data, let's split the dataset into features and labels.\n",
        "\n",
        "Create X and y datasets using .drop() and .loc() methods"
      ],
      "metadata": {
        "id": "cm_GGJgrzEGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the features dataset\n",
        "X = data.drop('Class', axis = 1)\n",
        "\n",
        "# Create the labels dataset\n",
        "y = data.loc[:,'Class']"
      ],
      "metadata": {
        "id": "lMl-9Or7zBTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Scaling\n",
        "\n",
        "Having features in different units or ranges can be problematic in deep learning. We need to scale all of the values between the 0 and 1 range.\n",
        "\n",
        "Use the minmax_scale() function of the sklearn library."
      ],
      "metadata": {
        "id": "uOvU9kNozlRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the features dataset and assign it to a variable.\n",
        "X_scaled = minmax_scale(X)\n",
        "\n",
        "# Create a DataFrame using the new variable\n",
        "\n",
        "X = pd.DataFrame(X_scaled)"
      ],
      "metadata": {
        "id": "sbZIvZtrzkI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we print the X data again so we can see the difference.\n",
        "\n",
        "\n",
        "Use the .head() method"
      ],
      "metadata": {
        "id": "zB7BNdHy0EgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the newly created DataFrame\n",
        "\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "1yE9B7jg0LvC",
        "outputId": "58e3fbae-1e7c-4f99-9e21-2871e7049b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.772274  0.772079  0.565604  0.841941  0.446429  0.871512  0.983209   \n",
              "1  0.617835  0.617480  0.436904  0.775906  0.342186  0.773229  1.000000   \n",
              "2  0.964674  0.913374  0.681733  0.933143  0.464896  0.981104  0.992537   \n",
              "3  0.761063  0.757502  0.554467  0.841456  0.430098  0.864727  0.983831   \n",
              "4  0.635159  0.657060  0.482240  0.759716  0.460470  0.784821  0.958955   \n",
              "\n",
              "         7         8         9   ...        24        25        26        27  \\\n",
              "0  0.767108  0.787438  0.000435  ...  0.395739  0.062495  0.053715  0.080752   \n",
              "1  0.611906  0.776970  0.000282  ...  0.350002  0.037387  0.040885  0.046033   \n",
              "2  0.956896  0.736842  0.000467  ...  0.472509  0.083531  0.089677  0.096843   \n",
              "3  0.755891  0.766502  0.000408  ...  0.687121  0.136202  0.278800  0.213061   \n",
              "4  0.633316  0.711253  0.000459  ...  0.464794  0.040608  0.054459  0.086850   \n",
              "\n",
              "         28        29        30        31        32        33  \n",
              "0  0.458253  0.455197  0.546327  0.673513  0.550537  0.494665  \n",
              "1  0.687312  0.599151  0.643352  0.538923  0.516341  0.494501  \n",
              "2  0.139263  0.194220  0.312066  0.777967  0.619782  0.573507  \n",
              "3  0.707125  0.657830  0.665214  0.436260  0.377376  0.366683  \n",
              "4  0.634560  0.615256  0.710963  0.581443  0.485820  0.395128  \n",
              "\n",
              "[5 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff62b978-9f8b-4d91-924f-895b7ec20282\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.772274</td>\n",
              "      <td>0.772079</td>\n",
              "      <td>0.565604</td>\n",
              "      <td>0.841941</td>\n",
              "      <td>0.446429</td>\n",
              "      <td>0.871512</td>\n",
              "      <td>0.983209</td>\n",
              "      <td>0.767108</td>\n",
              "      <td>0.787438</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>...</td>\n",
              "      <td>0.395739</td>\n",
              "      <td>0.062495</td>\n",
              "      <td>0.053715</td>\n",
              "      <td>0.080752</td>\n",
              "      <td>0.458253</td>\n",
              "      <td>0.455197</td>\n",
              "      <td>0.546327</td>\n",
              "      <td>0.673513</td>\n",
              "      <td>0.550537</td>\n",
              "      <td>0.494665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.617835</td>\n",
              "      <td>0.617480</td>\n",
              "      <td>0.436904</td>\n",
              "      <td>0.775906</td>\n",
              "      <td>0.342186</td>\n",
              "      <td>0.773229</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.611906</td>\n",
              "      <td>0.776970</td>\n",
              "      <td>0.000282</td>\n",
              "      <td>...</td>\n",
              "      <td>0.350002</td>\n",
              "      <td>0.037387</td>\n",
              "      <td>0.040885</td>\n",
              "      <td>0.046033</td>\n",
              "      <td>0.687312</td>\n",
              "      <td>0.599151</td>\n",
              "      <td>0.643352</td>\n",
              "      <td>0.538923</td>\n",
              "      <td>0.516341</td>\n",
              "      <td>0.494501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.964674</td>\n",
              "      <td>0.913374</td>\n",
              "      <td>0.681733</td>\n",
              "      <td>0.933143</td>\n",
              "      <td>0.464896</td>\n",
              "      <td>0.981104</td>\n",
              "      <td>0.992537</td>\n",
              "      <td>0.956896</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.000467</td>\n",
              "      <td>...</td>\n",
              "      <td>0.472509</td>\n",
              "      <td>0.083531</td>\n",
              "      <td>0.089677</td>\n",
              "      <td>0.096843</td>\n",
              "      <td>0.139263</td>\n",
              "      <td>0.194220</td>\n",
              "      <td>0.312066</td>\n",
              "      <td>0.777967</td>\n",
              "      <td>0.619782</td>\n",
              "      <td>0.573507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.761063</td>\n",
              "      <td>0.757502</td>\n",
              "      <td>0.554467</td>\n",
              "      <td>0.841456</td>\n",
              "      <td>0.430098</td>\n",
              "      <td>0.864727</td>\n",
              "      <td>0.983831</td>\n",
              "      <td>0.755891</td>\n",
              "      <td>0.766502</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>...</td>\n",
              "      <td>0.687121</td>\n",
              "      <td>0.136202</td>\n",
              "      <td>0.278800</td>\n",
              "      <td>0.213061</td>\n",
              "      <td>0.707125</td>\n",
              "      <td>0.657830</td>\n",
              "      <td>0.665214</td>\n",
              "      <td>0.436260</td>\n",
              "      <td>0.377376</td>\n",
              "      <td>0.366683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.635159</td>\n",
              "      <td>0.657060</td>\n",
              "      <td>0.482240</td>\n",
              "      <td>0.759716</td>\n",
              "      <td>0.460470</td>\n",
              "      <td>0.784821</td>\n",
              "      <td>0.958955</td>\n",
              "      <td>0.633316</td>\n",
              "      <td>0.711253</td>\n",
              "      <td>0.000459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.464794</td>\n",
              "      <td>0.040608</td>\n",
              "      <td>0.054459</td>\n",
              "      <td>0.086850</td>\n",
              "      <td>0.634560</td>\n",
              "      <td>0.615256</td>\n",
              "      <td>0.710963</td>\n",
              "      <td>0.581443</td>\n",
              "      <td>0.485820</td>\n",
              "      <td>0.395128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff62b978-9f8b-4d91-924f-895b7ec20282')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff62b978-9f8b-4d91-924f-895b7ec20282 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff62b978-9f8b-4d91-924f-895b7ec20282');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our features are ready for training. Now it's time to prepare the labels.\n",
        "\n",
        "Print y to take a look at it."
      ],
      "metadata": {
        "id": "juq_SAT80Qpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the y array\n",
        "\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEnBegdv0PzK",
        "outputId": "a3edf59e-8644-4236-fcc2-629c47c56a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      BERHI\n",
              "1      BERHI\n",
              "2      BERHI\n",
              "3      BERHI\n",
              "4      BERHI\n",
              "       ...  \n",
              "893    SOGAY\n",
              "894    SOGAY\n",
              "895    SOGAY\n",
              "896    SOGAY\n",
              "897    SOGAY\n",
              "Name: Class, Length: 898, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Artificial intelligence algorithms can't use any string data when training a model because mathematical operations can't be done on them.\n",
        "\n",
        "Use the LabelEncoder of the sklearn library to converting strings to integer. "
      ],
      "metadata": {
        "id": "0Ak2oZ8W06ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an LabelEncoder object.\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Convert string classes to integers using fit_transform() method\n",
        "y = encoder.fit_transform(y)\n"
      ],
      "metadata": {
        "id": "TZnaxgwe04hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we print y to check the result."
      ],
      "metadata": {
        "id": "eYLWTRUR2SPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the y array\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KfSd9DF2XOq",
        "outputId": "4a4a487f-a9ef-4895-f041-42ce2bedd69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
              "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
              "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
              "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
              "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting \n",
        "\n",
        "Great, that worked out as we wanted it to. We now split the dataset into training, validation and test datasets. In general, the ratio for splitting is 80% for training, 10% for validation and 10% for test sets.\n",
        "\n",
        "Use train_Test_split function of the sklearn library."
      ],
      "metadata": {
        "id": "R_UueMHO2abU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, create X_train, y_train and X_temporary and y_temporary datasets from X and y.\n",
        "X_train, X_temporary, y_train, y_temporary = train_test_split(X, y, train_size = 0.8)\n",
        "\n",
        "# Using the X_temporary and y_temporary dataset we just created create validation and test datasets.\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temporary, y_temporary, train_size = 0.5)\n"
      ],
      "metadata": {
        "id": "kMlXEL1t2v0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's print the total length of th initial dataset and lengths of the newly created datasets to check our results.\n",
        "\n",
        "Use the len() function to print the lengths."
      ],
      "metadata": {
        "id": "uJ1ltNKT3Pfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the lengths of the X, X_train, X_val and X_test\n",
        "\n",
        "print(f'Length of the dataset: {len(X)}')\n",
        "print(f'Length of the training dataset: {len(X_train)}')\n",
        "print(f'Length of the validation dataset: {len(X_val)}')\n",
        "print(f'Length of the test dataset: {len(X_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41Hp_w3F2-lP",
        "outputId": "04603c69-2dfd-434c-f0e8-0421ce5bcd7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the dataset: 898\n",
            "Length of the training dataset: 718\n",
            "Length of the validation dataset: 90\n",
            "Length of the test dataset: 90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constructing the Neural Network\n",
        "\n",
        "And with that our data is ready to be used in a model. We can move on to the exciting part: constructing a deep learning model. We'll use TensorFlow for this. To speed up the training time activate the GPU of Google Colab.\n",
        "\n",
        "Import TensorFlow"
      ],
      "metadata": {
        "id": "JVs3A5aY3QIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "_8fbO0H74gO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by creating a model object using Sequential API of Keras.\n",
        "\n",
        "Use tf.keras.Sequential() to create a model object"
      ],
      "metadata": {
        "id": "R-Lr3Uso4nvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model object\n",
        "\n",
        "model = tf.keras.Sequential()"
      ],
      "metadata": {
        "id": "Vla1hQYO4mpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input Layer\n",
        "\n",
        "First, we construct an input layer and assing it to a variable. The first argument is the number of nodes we want in that hidden layer. Only for the input layer we have to set input_shape argument which is number of columns , in this case 34. For the activation function we specify \"ReLU\".\n",
        "\n",
        "Use tf.keras.layers.Dense() to create the layer.\n",
        "\n",
        "Use .add() method of the object to add the layer."
      ],
      "metadata": {
        "id": "8n29r9JP40ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an input layer \n",
        "input_layer = tf.keras.layers.Dense(4096, input_shape = (34,), activation = 'relu')\n",
        "\n",
        "# Add input layer to model object\n",
        "model.add(input_layer)"
      ],
      "metadata": {
        "id": "S_1RWCoM4zwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hidden Layer\n",
        "\n",
        "Next, we need to add the hidden layers. We'll add 4 hidden layers each with 4096 nodes. Again, we specify ReLU as the activation functions and 0.5 dropouts.\n",
        "\n",
        "Use tf.keras.layers.Dense() to create the layers.\n",
        "\n",
        "Use .add() method of the object to add the layer."
      ],
      "metadata": {
        "id": "KaW5FKZDA1mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the first hidden layer with 4096 nodes and relu activation function\n",
        "model.add(tf.keras.layers.Dense(4096, activation = 'relu'))\n",
        "\n",
        "# Add 0.5 dropout\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "# Add the second hidden layer with 4096 nodes and relu activation function\n",
        "model.add(tf.keras.layers.Dense(4096, activation = 'relu'))\n",
        "\n",
        "# Add 0.5 dropout\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "# Add the third hidden layer with 4096 nodes and relu activation function\n",
        "model.add(tf.keras.layers.Dense(4096, activation = 'relu'))\n",
        "\n",
        "# Add 0.5 dropout\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "# Add the fourth hidden layer with 4096 nodes and relu activation function\n",
        "model.add(tf.keras.layers.Dense(4096, activation = 'relu'))\n",
        "\n",
        "# Add 0.5 dropout\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n"
      ],
      "metadata": {
        "id": "Ov3eQHu-BMUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output Layer\n",
        "\n",
        "As the last part of our neural network, we add the output layer. The number of nodes will be equal to the number of target classes which is 7 in our case. We'll use the softmax activation function in the output layer."
      ],
      "metadata": {
        "id": "eQm1ooIBCvQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the output layer\n",
        "model.add(tf.keras.layers.Dense(7, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "6OOxeLJJCr-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer \n",
        "\n",
        "Now we have the structure of our model. To configure the model for training we'll use the .compile() method. Inside the compile method we have to define the following:\n",
        "\n",
        "* \"Adam\" for optimizer\n",
        "\n",
        "* \"Sparse Categorical Crossentropy\" for the loss function\n",
        "\n",
        "Construct the model with the .compile() method"
      ],
      "metadata": {
        "id": "CzCG-0IlDFcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "qb_JFTuEDEtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model\n",
        "\n",
        "It's time to train the model. We'll give the X_train and y_train datasets as the first wto arguments. These will be used for training. And with the validation_data parameter we'll give the X_val and y_val as a tuple.\n",
        "\n",
        "* Use .fit() method of the model object for the training."
      ],
      "metadata": {
        "id": "qMfNo_bMDjVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model for 100 epochs\n",
        "results = model.fit(X_train, y_train, epochs = 100, validation_data = (X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgCPlGJ1ETQm",
        "outputId": "1ccb15a6-eaca-41f4-ba48-b27ead9009a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 4s 26ms/step - loss: 1.6604 - accuracy: 0.3691 - val_loss: 0.8462 - val_accuracy: 0.6667\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.8242 - accuracy: 0.6908 - val_loss: 0.8757 - val_accuracy: 0.6556\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.6946 - accuracy: 0.7354 - val_loss: 0.6356 - val_accuracy: 0.7333\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.5670 - accuracy: 0.7953 - val_loss: 0.8901 - val_accuracy: 0.7444\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.5715 - accuracy: 0.7841 - val_loss: 0.4733 - val_accuracy: 0.8222\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.4897 - accuracy: 0.8036 - val_loss: 0.5923 - val_accuracy: 0.8111\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.5878 - accuracy: 0.7688 - val_loss: 0.5785 - val_accuracy: 0.8222\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4594 - accuracy: 0.8162 - val_loss: 0.5351 - val_accuracy: 0.7889\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4128 - accuracy: 0.8315 - val_loss: 0.6187 - val_accuracy: 0.8333\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 22ms/step - loss: 0.5357 - accuracy: 0.7883 - val_loss: 0.6418 - val_accuracy: 0.7333\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.4074 - accuracy: 0.8287 - val_loss: 0.5056 - val_accuracy: 0.8333\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4675 - accuracy: 0.8022 - val_loss: 0.4783 - val_accuracy: 0.8556\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3938 - accuracy: 0.8301 - val_loss: 0.5478 - val_accuracy: 0.8000\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3791 - accuracy: 0.8426 - val_loss: 0.4854 - val_accuracy: 0.8667\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3573 - accuracy: 0.8579 - val_loss: 0.7423 - val_accuracy: 0.7667\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.4928 - accuracy: 0.8189 - val_loss: 0.4536 - val_accuracy: 0.8667\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.3770 - accuracy: 0.8384 - val_loss: 0.5378 - val_accuracy: 0.8111\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.4094 - accuracy: 0.8496 - val_loss: 0.5965 - val_accuracy: 0.8556\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3556 - accuracy: 0.8677 - val_loss: 0.5345 - val_accuracy: 0.8778\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.6461 - accuracy: 0.7813 - val_loss: 0.8339 - val_accuracy: 0.7333\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.4664 - accuracy: 0.8189 - val_loss: 0.5169 - val_accuracy: 0.7889\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.4021 - accuracy: 0.8538 - val_loss: 0.6085 - val_accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.3516 - accuracy: 0.8788 - val_loss: 0.5105 - val_accuracy: 0.7889\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3688 - accuracy: 0.8538 - val_loss: 0.5355 - val_accuracy: 0.8222\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3601 - accuracy: 0.8593 - val_loss: 0.4884 - val_accuracy: 0.8778\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3115 - accuracy: 0.8705 - val_loss: 0.6701 - val_accuracy: 0.8111\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.3619 - accuracy: 0.8649 - val_loss: 0.7115 - val_accuracy: 0.7778\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.4895 - accuracy: 0.8384 - val_loss: 0.5647 - val_accuracy: 0.8000\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.5095 - accuracy: 0.8092 - val_loss: 0.6204 - val_accuracy: 0.8556\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.3410 - accuracy: 0.8830 - val_loss: 0.9326 - val_accuracy: 0.7556\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3560 - accuracy: 0.8482 - val_loss: 0.4674 - val_accuracy: 0.8667\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3325 - accuracy: 0.8816 - val_loss: 0.6639 - val_accuracy: 0.8222\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3322 - accuracy: 0.8816 - val_loss: 0.5429 - val_accuracy: 0.8667\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3671 - accuracy: 0.8733 - val_loss: 0.4048 - val_accuracy: 0.8889\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3533 - accuracy: 0.8691 - val_loss: 0.3888 - val_accuracy: 0.8778\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3538 - accuracy: 0.8900 - val_loss: 0.4797 - val_accuracy: 0.8333\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.3968 - accuracy: 0.8468 - val_loss: 0.5074 - val_accuracy: 0.7667\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3749 - accuracy: 0.8552 - val_loss: 0.5347 - val_accuracy: 0.8556\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3086 - accuracy: 0.8928 - val_loss: 0.7626 - val_accuracy: 0.8333\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3629 - accuracy: 0.8663 - val_loss: 0.4552 - val_accuracy: 0.8556\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.3564 - accuracy: 0.8677 - val_loss: 0.5980 - val_accuracy: 0.8222\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2519 - accuracy: 0.9011 - val_loss: 0.5258 - val_accuracy: 0.8778\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3070 - accuracy: 0.8983 - val_loss: 0.5583 - val_accuracy: 0.8667\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3257 - accuracy: 0.8900 - val_loss: 0.6004 - val_accuracy: 0.8556\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2832 - accuracy: 0.8969 - val_loss: 0.5575 - val_accuracy: 0.8333\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3275 - accuracy: 0.8844 - val_loss: 0.4571 - val_accuracy: 0.8000\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.3245 - accuracy: 0.8802 - val_loss: 0.4964 - val_accuracy: 0.8778\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2792 - accuracy: 0.9123 - val_loss: 0.7155 - val_accuracy: 0.8222\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.2844 - accuracy: 0.8942 - val_loss: 0.4810 - val_accuracy: 0.8889\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2815 - accuracy: 0.8942 - val_loss: 0.5879 - val_accuracy: 0.8667\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.2815 - accuracy: 0.8955 - val_loss: 0.5710 - val_accuracy: 0.7889\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.3062 - accuracy: 0.8886 - val_loss: 0.5115 - val_accuracy: 0.8778\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.2635 - accuracy: 0.8969 - val_loss: 0.4892 - val_accuracy: 0.8778\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3653 - accuracy: 0.8774 - val_loss: 0.5810 - val_accuracy: 0.8000\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2548 - accuracy: 0.9095 - val_loss: 0.5177 - val_accuracy: 0.8444\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2648 - accuracy: 0.9011 - val_loss: 0.5074 - val_accuracy: 0.9000\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.2296 - accuracy: 0.9081 - val_loss: 0.6868 - val_accuracy: 0.8444\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2428 - accuracy: 0.9123 - val_loss: 0.5620 - val_accuracy: 0.8222\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2927 - accuracy: 0.8788 - val_loss: 0.5313 - val_accuracy: 0.8111\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2390 - accuracy: 0.9039 - val_loss: 0.5065 - val_accuracy: 0.8444\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2298 - accuracy: 0.9192 - val_loss: 0.6151 - val_accuracy: 0.8778\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2811 - accuracy: 0.8914 - val_loss: 0.5521 - val_accuracy: 0.8000\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3224 - accuracy: 0.8760 - val_loss: 0.5552 - val_accuracy: 0.8222\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.3831 - accuracy: 0.8482 - val_loss: 0.5491 - val_accuracy: 0.8889\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.2323 - accuracy: 0.9067 - val_loss: 0.6049 - val_accuracy: 0.9000\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.3120 - accuracy: 0.8872 - val_loss: 0.4535 - val_accuracy: 0.8667\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2225 - accuracy: 0.9150 - val_loss: 0.3956 - val_accuracy: 0.9000\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2675 - accuracy: 0.9109 - val_loss: 0.4737 - val_accuracy: 0.8778\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2303 - accuracy: 0.9136 - val_loss: 0.4740 - val_accuracy: 0.9111\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 1s 22ms/step - loss: 0.2514 - accuracy: 0.9011 - val_loss: 0.5508 - val_accuracy: 0.8778\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2573 - accuracy: 0.8969 - val_loss: 0.4583 - val_accuracy: 0.8889\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2514 - accuracy: 0.9095 - val_loss: 0.6168 - val_accuracy: 0.8222\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.2573 - accuracy: 0.8983 - val_loss: 0.5394 - val_accuracy: 0.8889\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2123 - accuracy: 0.9206 - val_loss: 0.4800 - val_accuracy: 0.8667\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.1791 - accuracy: 0.9248 - val_loss: 0.4863 - val_accuracy: 0.8778\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.1894 - accuracy: 0.9192 - val_loss: 0.4256 - val_accuracy: 0.8889\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2538 - accuracy: 0.9109 - val_loss: 0.6687 - val_accuracy: 0.8444\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.2425 - accuracy: 0.9067 - val_loss: 0.4169 - val_accuracy: 0.9111\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2068 - accuracy: 0.9206 - val_loss: 0.3626 - val_accuracy: 0.9000\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.1965 - accuracy: 0.9220 - val_loss: 0.5174 - val_accuracy: 0.8778\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2453 - accuracy: 0.9136 - val_loss: 0.4822 - val_accuracy: 0.8444\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2795 - accuracy: 0.8969 - val_loss: 0.4788 - val_accuracy: 0.8556\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2112 - accuracy: 0.9150 - val_loss: 0.4842 - val_accuracy: 0.9000\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3401 - accuracy: 0.8886 - val_loss: 0.5116 - val_accuracy: 0.8667\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2187 - accuracy: 0.9178 - val_loss: 0.5286 - val_accuracy: 0.9000\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3339 - accuracy: 0.8705 - val_loss: 0.4717 - val_accuracy: 0.8778\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.2270 - accuracy: 0.9248 - val_loss: 0.4149 - val_accuracy: 0.8889\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2194 - accuracy: 0.9053 - val_loss: 0.9488 - val_accuracy: 0.8111\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2370 - accuracy: 0.9178 - val_loss: 0.4670 - val_accuracy: 0.8889\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2221 - accuracy: 0.8955 - val_loss: 0.6266 - val_accuracy: 0.8667\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2724 - accuracy: 0.8928 - val_loss: 0.5137 - val_accuracy: 0.9000\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2607 - accuracy: 0.8983 - val_loss: 0.4626 - val_accuracy: 0.8667\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.2292 - accuracy: 0.9011 - val_loss: 0.4466 - val_accuracy: 0.8667\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.2027 - accuracy: 0.9053 - val_loss: 0.5479 - val_accuracy: 0.8667\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.2321 - accuracy: 0.9095 - val_loss: 0.4197 - val_accuracy: 0.9000\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.2317 - accuracy: 0.9109 - val_loss: 0.5193 - val_accuracy: 0.8778\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.2258 - accuracy: 0.9178 - val_loss: 0.4208 - val_accuracy: 0.8778\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 22ms/step - loss: 0.2495 - accuracy: 0.9164 - val_loss: 0.6366 - val_accuracy: 0.8778\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2134 - accuracy: 0.9192 - val_loss: 0.4673 - val_accuracy: 0.8556\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3063 - accuracy: 0.8858 - val_loss: 0.5692 - val_accuracy: 0.8889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the Result\n",
        "\n",
        "After the model is trained we can create a graph to visualize the chamge of loss over time. Results are held in:\n",
        "\n",
        "* results.history[\"loss\"]\n",
        "\n",
        "* results.history[\"val_loss\"]\n",
        "\n",
        "Use plt.show() to display the graph."
      ],
      "metadata": {
        "id": "2Ha2LieWFlrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training loss\n",
        "plt.plot(results.history['loss'], label = 'Train')\n",
        "\n",
        "# Plot the validation loss\n",
        "plt.plot(results.history['val_loss'], label = 'Test')\n",
        "\n",
        "# Name the x and y axises\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Put legend table\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "uf0xBTZKFMnK",
        "outputId": "0e187ead-c873-4769-97ad-9bc69b9a15b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance Evaluation\n",
        "\n",
        "Finally, we are going to use the test dataset we created to evaluate the performance of the model.\n",
        "\n",
        "Use test_on_batch() method with test dataset as parameter"
      ],
      "metadata": {
        "id": "dpP1MXZ_Gzvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance\n",
        "test_result = model.test_on_batch(X_test, y_test)\n",
        "\n",
        "# Print the result\n",
        "print(test_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tjpTs2CGmw4",
        "outputId": "e203a60c-e89a-4e1d-9169-695ac918a5d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.2716849446296692, 0.9222221970558167]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AI9041 Convolution and Filters\n",
        "\n",
        "Hello and welcome back! Look around, we perceive the world in 3D. Beautifully composed music, images, videos. They are all in 3D for us humans, but what about computers? What do they see, how do they perceive the world around them? Well, they only see numbers. The images are numbers, the videos are numbers, the audios are numbers, even texts are numbers. Of course these numbers relate to each other, but how do computers know how?\n",
        "\n",
        " \n",
        "\n",
        "Let’s start with an example. Here we have images of some cars and airplanes, we want to differentiate these two classes. Computers see these images as numbers and if we want to teach computers how to classify them, these numbers need to make sense. Each number alone might not be enough to tell anything about the image. But all of them together will hold useful information. So, computers have to comprehend these numbers in their context, where they are located and how they relate to each other. For this reason, spatial information can be very important. In this video, we will talk about spatial information, convolution and some conventional image processing techniques. Images are 2-dimensional arrays or matrices. In grayscale images, there is only 1 channel and in colored images, there are three channels RGB: red, green, and blue. A pixel in the grayscale image is a single value. And a pixel in an RGB image is an array of 3 values. The value can usually be between 0 to 255 or it can be scaled to 0 to 1. Here 0 represents no color and 1 represents full color. Each pixel can be used as a feature. Thus, the input to the neural network,, is the total number of pixels in the image. For example, in this 32 by 32 image, there are 1024 pixels in total. Since it is grayscale, each pixel only has 1 value, so in order to feed this to our neural network, we need an input layer of 1024 units.\n",
        "\n",
        " \n",
        "\n",
        "This number is big and it will cost us some computation time. But there is a bigger problem with using pixels as features. The model cannot identify which pixels are closer to each other and which ones are far. As you can see, this pixel is closer to this one compared to this pixel. However, a neural network does not discriminate between different pixels. If we want our model to perform better, we need features that consider neighboring pixels, that give us this spatial information. For this, we need to study one of the conventional methods that were used to extract information from the images: Convolution. It is a simple mathematical operation where a weighted sum is calculated of each element and its neighbors. This helps the computer to somewhat understand the spatial context of the data. In convolution, we have a predefined kernel which is also referred to as convolutional filter. We multiply the elements of the kernel, with the elements in the window in the top left corner of the image. Element by element. Then we add these products. And the sum of the products is a new pixel value which is written on the output grid. Then the kernel slides one step to the right side, and the sum of products with this window is calculated, and it is written on the output grid. The kernel slides again and the process is repeated until the kernel has slid over the entire image and the output grid is complete. You might have noticed that the output does not have the same dimensions as the input image due to the edges. But don’t worry now, we will talk about them in upcoming videos.\n",
        "\n",
        " \n",
        "\n",
        "Convolution is a linear process. This means the value of the output pixel is a linear combination of the neighboring input pixels. The most important application of convolution is that, it can extract features that account for the spatial context of the image. For example, consider this vertical edge detection filter. Whenever this filter sees a sudden jump vertically, the corresponding pixel in the output will spike. Similarly, we have a horizontal edge detection which detects the horizontal edges. There are other types of edge detection filters. For example, the Sobel filter. There is also a Laplacian filter. It highlights regions of rapid intensity change and is therefore often used for edge detection. These convolutional kernels are used to extract the important features from the image. One kernel might not be enough to extract the features. So, multiple kernels are used to compute multiple feature maps. And these feature maps can be fed into our neural network. Now, our neural network has context spatial information on more than just the pixels. Convolutional filter can denoise an input. For example, using the so-called mean filter, convolution can help to reduce the unwanted noise from an image. The mean filter averages the content of each window of the input image, and outputs a smoother version of it without any sudden jumps. Now, the salt and pepper noise in the input is removed by taking the local averages. So, when the pixel is black and neighboring pixels are white, the result will be very light gray. And when the pixel is white and all its neighbors are black, the result would be dark gray. Thus, it smoothens the input. So far, we have seen examples from images because it is easier for us humans to comprehend how convolution works with visual data. Images are 2D data but the convolutional filters can be applied to 1D or 3D data as well, they don’t always have to be 2D. For example, we might want to use 1D convolution for audio or textual data, 2D for images and 3D for videos.\n",
        "\n",
        " \n",
        "\n",
        "In this video, we learned that using pixels directly as features may not give all the required information computers need to understand the data. We learned what convolution is, how it is performed and we discussed different types of convolutional kernels. Finally, we discussed how these kernels are used to extract features, which deliver the needed spatial information. The convolutional filters that we discussed were engineered by great computer scientists and mathematicians, but there are only a limited number of defined convolutional filters. And this, limits the information we can extract from the input. But what if the filter values were not fixed and were learned by our model? Now, we can have as many filters as we like and now more information can be extracted. How to do it? Well, stay tuned, that is for our next video. Convolutional Neural Networks, or as we call them CNNs. See you there!"
      ],
      "metadata": {
        "id": "odQKKzXCj5BT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AI9042 Convolutional Neural Network\n",
        "\n",
        "Hello again! In the previous video, we learned about convolution and convolutional kernels or filters. We also discussed some of the predefined convolutional filters. But what about the ones that are not predefined? In this video, we will find out how the filter values can be learned by the model, and how feature extraction can happen without manually set filters. All of this will help us learn the most crucial component in almost all the deep learning architectures: Convolutional Neural Networks (CNNs).\n",
        "\n",
        " \n",
        "\n",
        "Convolutional Neural Networks improve the performance of classification models. In addition, they serve as the basis for more complicated tasks and, can be used to solve some common computer vision problems. One such problem is: Semantic segmentation. In semantic segmentation, every pixel in the image is classified. In practice, such models can be used to segment invasive and non-invasive tumor tissues in medical images. Another computer vision problem: Object detection. It is the model which detects different objects in the image and draws bounding boxes around them. Object detection is often used by street surveillance systems that are able to count the people on the streets. Instance Segmentation. Instance segmentation is a combination of semantic segmentation and object detection. It detects each object uniquely and segments it. It is used in autonomous vehicles. It identifies different cars and classifies each pixel of them. These tasks are pretty exciting, aren’t they? In order to understand the complex architectures of these models, we need to understand what CNNs do and how they do it?\n",
        "\n",
        " \n",
        "\n",
        "Convolutional Neural Networks are made of convolutional kernels with learnable filter values. We refer to these filter values as weights because, in convolution, these values are used to take the weighted sum of the input window. Similar to artificial neural networks, we also have a bias term for these filters to accommodate biases of the data. Also, similar to ANNs, these weights and biases are randomly initialized and learned iteratively. In short, we want to learn the features and automate the extraction process so that hand-crafted features are not required. Instead of hard-coded or handcrafted boring filters, we might have some interesting filters like these. You can see some of them will function as edge detectors or blob detectors. When you look at people around you, you see everyone has a different face, unless they are identical twins of course. Even though everyone has a nose, two eyes, two ears, lips, and hair, your brain can still identify everyone individually. What if you only relied on pixel-level information? Or even the information about the edges, sizes, and colors of these facial features? You might have some problems recognizing your friends. This is because your brain does not rely on low-level or simple high-level features. It combines the information from these edges, sizes, and colors and creates even complex features like the shape of the nose, hairstyle, or facial expressions.\n",
        "\n",
        " \n",
        "\n",
        "So why should we limit ourselves to only a simple convolutional neural network? Instead, we can have multiple convolutional layers in the network. Each layer has filters with weights and biases, and an activation function. Here every layer extracts the information from the previous layer and builds up complex information from simple pixel-wise raw data. We saw how Artificial Neural Networks try to mimic the neural networks of our brain. The weights and biases of the neural network are learned according to the loss function. The input to output pipeline is defined, which has components like Convolutional layers and some fully connected neural network layers. The loss is defined, and the aim is to minimize the loss. The CNN model is trained similarly to the ANN, through backpropagation and gradient descent. Nevertheless, the model might learn different features for different types of problems. For example, the model used for classifying different animals may want to use very different features than the model that is trying to locate the animal’s position in the image. The model used for classification might want to extract features like the shape of ears, length of tail, or atmosphere around the animal. Whereas the model used for locating the animals might want to use features like a sudden change in the pixel values or maybe contrastive colors. One problem associated with the convolutional operation is that, it does not work on the borders of the input. When we apply the convolution to an image, the kernel is fit to the upper left corner and slides right at each step. In this process, the borders do not have their pixels in the output and therefore the dimension is reduced. And having multiple convolutional layers means reducing the dimensions of features multiple times. If there is important information on the border, the results might miss it, and we need to fix this problem.\n",
        "\n",
        " \n",
        "\n",
        "For example, if there is a boat in the center and the water on the edges of the images, the model considers the water to be an important marker to classify an object as a boat. It might not classify it as a boat if it doesn’t see water in the scene. To prevent information loss at the borders, we concatenate some numbers to the borders of the input frame. This process is called padding. We can pad by zeros or any other constant, or we can pad by mirroring the edge. Padding helps to retain the shape of the input when extracting the features and allows us to take edges and corners of the input into account. Now we can keep the feature maps with the same dimension as the input image. But some features extracted from these convolutional layers can be redundant, useless, or even add noise to our model. Therefore we also have to make sure to use only the useful or more meaningful features. This will increase the model’s performance, and reduce the computational costs by decreasing the parameters. The Pooling layer is responsible for reducing the size of the Convolved Features. There are two most common types of pooling: max pooling and average pooling. In the max-pooling layer, the input is divided into grids, and the maximum value of each block is the layer’s output. In the average pooling layer, each block’s average value is the layer’s output. Usually, max pooling is used in convolutional neural networks because it significantly removes the noise. There are no weights or biases of the pooling layer. We can say that there are no learnable parameters in the pooling layer, which significantly reduces the feature block size. With max-pooling layers added to our network after every convolutional layer, a typical convolutional neural network model for classification looks like this.\n",
        "\n",
        " \n",
        "\n",
        "In the first half of the architecture, features are extracted from the image using convolutional and pooling layers. We can say that this block has all the necessary information about the input encoded into it. We flatten it to 1D so that our fully-connected neural network can take it as an input and perform the classification task. It takes millions of samples to train a good classification model based on this architecture. And deep learning models have to be trained from scratch every time. Wouldn’t it be great if there was a way to transfer already learned information from a trained model to an untrained model? We have just seen that CNN based feature extractors can be used to extract some useful features that we can input to our network. Fortunately, there are some existing models that have a well-trained feature extractor. So instead of training the feature extractor from scratch, we can use the weights of pretrained models and only train the classification part of the model according to the given problem. In this case, we already have optimized values for the weights and biases, and there is no need to adjust them again. This process is called transfer learning and it greatly helps when we are training a CNN model with less data.\n",
        "\n",
        " \n",
        "\n",
        "Wow. The good news is that, you have learned how machines can extract the features themselves, and now you do not need to worry about finding useful features for the model. The model will find them by itself. We have learned a very important chapter of deep learning: CNNs. We have also discussed pooling layers and padding. That is all for now. Now, it is time to practice what you have learned. In the next video, we will build a convolutional neural network that takes images as input and extracts the features, and then classifies them. See you there!"
      ],
      "metadata": {
        "id": "mzgBQH3wk1uM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AI9051 Build a Convolutional Neural Network\n",
        "\n",
        "Hello again! In this project we will gain some hands-on experience in “Convolutional Neural Networks”, CNNs. With the help of TensorFlow’s Sequential API we learnt in the previous project, we’ll create a model object and add convolutional layers, dropouts etc. After that we’ll compile and train the model and check the results. Before we start, don’t forget to change the Runtime type to GPU in Google Colab. The dataset we’ll use for this project is called CIFAR-10. This time, we will not have numerical data and there are no predefined features. Instead, the dataset consists of 60 000 32 by 32 color images of 10 classes, with 6000 images per class. The classes are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck. This is a multiclass classification problem and it is perfectly suitable for a convolutional neural network to solve.\n",
        "\n",
        " \n",
        "\n",
        "Let’s dive into coding! We start by importing the required libraries. In this project we will need Tensorflow, NumPy and matplotlib. The CIFAR-10 dataset is included in the Keras module. It is already divided into train and test datasets so we can easily download it and assign it to the X_train, y_train, X_test and y_test variables. If this wouldn’t be the case, we would have to create these sets manually. We can print the lengths of the X_train and X_test sets using the len function to see how they are distributed. The ratio is 5 to 1. Before we move on with the preprocessing of the data, let’s take a look at a sample to see what we are dealing with. We pick a random index in the X test set and print it. The numbers we see here are pixel values. This is how computers see images. But like this, it doesn’t mean much to us. Let’s visualize this sample. We can use a function included in the Matplotlib library, imshow. imshow takes a Numpy array as input and shows us the corresponding image. Let’s also print the shape of the image. This tuple means that we have a 32 by 32 image with 3 channels. Note that RGB images, in other words color images, have 3 channels for red, green and blue. Great! With this knowledge we can adjust our dataset.\n",
        "\n",
        " \n",
        "\n",
        "Remember that we need three unique datasets to train, validate and test a deep learning model. Since we already have train and test sets, we just need some data for validation. We can use the last 10 000 images of the train set for this. Let’s set it up. Then, we check the lengths of the sets again. 4 to 1 to 1. This ratio is appropriate. As we did with the numerical data in our last project, normalizing the pixel values of the image will greatly help with model training. Pixel values in the images are between 0 and 255. By dividing these values by 255 we’ll scale them between 0 and 1. That was it for the preprocessing of the data! We can create our model now. First things first; let’s create a model object. Now, here comes the exciting part, are you ready to add the convolution layers? With Keras’s Conv2D layer, we add our first convolution layer. There are parameters we need to specify: For the “Number of nodes”, we put 32 and for the “Kernel size” we specify 3 by 3. There is also the parameter “Strides”: This parameter specifies the strides of the convolution kernel along the height and width of the image. For example, if the stride is 1, the filter will move 1 pixel at a time. Next, we need to specify the “Padding” and “Activation function”. As you might remember, we pad to prevent information loss on the borders of the images. We want the padding to be the same as the border values and we put ReLU as the activation function. We could use any activation function here, activation functions are hyperparameters so we have to figure out the best one by trial and error. Other functions that could fit this problem are: “TanH”, “Leaky ReLU” or “ELU”. The last parameter we set is the “Input shape”. Our input has the shape (32,32,3).\n",
        "\n",
        " \n",
        "\n",
        "The next part is to add one convolution layer, one max pooling layer and one convolution layer again. Remember that we add the max pooling layer to reduce the size of the image and make some detected features more robust. This also speeds up the training. We will specify 64 nodes for the convolution layers this time. This is a number we choose randomly and can adjust later on. The remaining parameters are the same as in the input layer. Now we move on to the classification part. In order to connect the 2D convolution layers and 1D dense layers we have to bring them to the same dimensions. This is where the “flatten” method comes to our help. In other words we take all pixel values and put them on a 1D array one by one. After that, we add two dense layers. Each with 64 nodes, ReLU activations and 0.5 dropouts. Don’t forget that these are arbitrary numbers that can be adjusted later on to improve the performance. It’s time for the output layer. Since we have 10 classes we add 10 nodes and use the Softmax activation function. Remember that for multiclass classification problems, we use Softmax at the output layer. Finally, we compile the model. We define the optimizer “Adam”, our go-to optimizer, and since we are trying to solve a multiclass classification problem we use the “Sparse Categorical Cross Entropy” loss function. With this, our model is ready to be trained!\n",
        "\n",
        " \n",
        "\n",
        "In our dataset we have 60000 images, we use 40000 of them for training. But we have to be careful! Training with all of these pictures at the same time would quickly drain our memory and other hardware resources. To prevent this, we use a technique called mini-batching. With mini-batching, instead of looking at all samples at the same time, the model will only see a small number of samples at a time. This method has many advantages; mini-batching increases model training significantly by speeding up the training and using less memory. Also if we have more than one GPU we can use these GPUs to train different batches at the same time. So, we need to add a new parameter here called “batch_size”. And as you can probably guess, it is another hyperparameter, meaning we’ll have to find the optimum value for it. Sometimes lower is better and other times higher is better. But since computers work with binary numbers, choosing a number which is a power of 2 is highly recommended so that the computation speed is increased. Let’s try it out with a batch size of 128 for 50 epochs. This will take some time.\n",
        "\n",
        " \n",
        "\n",
        "Our training is done! And what comes after the training? The performance evaluation. We’ll start by creating a graph to visualize the change of loss over time. Now, let’s do the same thing for accuracy. We see in the graphs that, around the 20th epoch, the model started to overfit. We can say that because both training and evaluation lines start to get further apart from each other. One method of preventing this would be using the “Early Stopping” method. Early stopping is stopping the training process around the epoch which model starts to overfit. So if we train the model only for 20 epochs we would prevent overfitting. We can also use the test dataset to calculate the loss and accuracy and get more insights about performance of the model. We have a model with 1.21 loss and over 70% accuracy. If these results are enough for the problem at hand, we don’t have to further optimize the model. But remember that we want the loss to be as close to 0 as possible. And accuracy as close to 100% as possible. So, if necessary, we can do hyperparameter optimization to try getting closer to these values. Let’s check the ship image from previous cells to see if it was classified correctly. We use the reshape method because the predict method expects a batch of images to predict. But we want to make prediction on a single image. By reshaping the image to (1,32,32,3) we say that we have one image of 32 by 32 by 3. Then we print the prediction results.The output gives the probability of an image belonging to each class. To find the highest probability we can use argmax and max methods. argmax returns the index of the highest value, which is the predicted class, and max returns the probability. Let’s find these and assign them to variables.\n",
        "\n",
        " \n",
        "\n",
        "Let’s print the prediction. This image belongs to class 8 with probability of 0.99. So,this means that there is a ninety nine percent probability that it belongs to class 8. We know that class 8 is the “ship” class. So we can say that model predicted this image correctly. We said earlier that we have a slight overfitting situation. But we can overcome this by fine-tuning the hyperparameters. Now change the following parameters to see if you come up with a better performing model: number of convolutional layers, number of kernels in convolutional layers, kernel size, strides, activation functions, number of hidden layers in classification part, number of nodes in hidden layers in classification part, optimizer, batch size, number of epochs. After that, check a couple of images yourself to see if they are predicted correctly. You can use the course hub to exchange with our experts and your peers and share your results if you like!\n",
        "\n",
        " \n",
        "\n",
        "In this project we learned how to create a convolutional neural network model to classify images. In this exercise, we also explored a practical concept called mini-batching , which is highly important when it comes to training CNNs. See you in the next session!"
      ],
      "metadata": {
        "id": "ouvDApARp9rU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we will build a convolutional neural network to solve a multiclass image classification problem. For this we'll use the \"CIFAR-10\" dataset available on Keras. It includes 60000 32 by 32 images of 10 classes.\n",
        "\n",
        "#### Importing the required libraries\n",
        "\n",
        "We'll start with importing required libraries.\n",
        "\n",
        "Use the keyword \"import\"."
      ],
      "metadata": {
        "id": "QD2Q8IDWYjKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import Numpy and Matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "fW8YdE9bkDbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset\n",
        "\n",
        "Let's download the CIFAR-10 dataset which is included in Keras and assign it to the corresponding variables X_train, y_train, X_test, y_test. \n",
        "\n",
        "Use the datasets.cifar10.load_data() function of the Keras."
      ],
      "metadata": {
        "id": "91pjPgeWaDHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the cifar-10 dataset included in Keras.\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "GxR2fdECaB23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can print the number of samples in the X_train and X_test datasets to see how the dataset is distributed.\n",
        "\n",
        "Use f-strings for this."
      ],
      "metadata": {
        "id": "3sH9Iz-Da0Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of samples\n",
        "print(f\"X_train: {len(X_train)}\")\n",
        "print(f\"X_test: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz6rOkZ-ak7y",
        "outputId": "13fd2ee6-533b-458f-db3f-ff1860e94976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: 50000\n",
            "X_test: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we move on with the preprocessing of the data, we can print a random sample to see that the data looks like."
      ],
      "metadata": {
        "id": "TivTAiUBbcvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a sample from X_test dataset\n",
        "print(X_test[789])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5AevnWDbYOz",
        "outputId": "6780b234-7e24-45ba-a74d-caa791bb8297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[100 111 134]\n",
            "  [ 98 110 132]\n",
            "  [ 98 109 131]\n",
            "  ...\n",
            "  [ 69  89 114]\n",
            "  [ 67  87 113]\n",
            "  [ 66  86 111]]\n",
            "\n",
            " [[ 98 109 131]\n",
            "  [ 95 106 128]\n",
            "  [ 94 105 127]\n",
            "  ...\n",
            "  [ 65  85 110]\n",
            "  [ 64  84 109]\n",
            "  [ 63  83 107]]\n",
            "\n",
            " [[ 94 105 127]\n",
            "  [ 92 103 125]\n",
            "  [ 92 103 125]\n",
            "  ...\n",
            "  [ 63  83 108]\n",
            "  [ 62  82 107]\n",
            "  [ 60  80 105]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 13  27  40]\n",
            "  [ 12  26  39]\n",
            "  [ 12  26  39]\n",
            "  ...\n",
            "  [  4   6  21]\n",
            "  [  5   7  22]\n",
            "  [  4   7  22]]\n",
            "\n",
            " [[ 12  24  38]\n",
            "  [ 14  26  39]\n",
            "  [  9  21  34]\n",
            "  ...\n",
            "  [  3   5  19]\n",
            "  [  3   5  20]\n",
            "  [  5   7  22]]\n",
            "\n",
            " [[ 14  23  34]\n",
            "  [ 12  21  31]\n",
            "  [  9  19  29]\n",
            "  ...\n",
            "  [  4   4  17]\n",
            "  [  4   5  18]\n",
            "  [  5   5  18]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The numbers we see here are pixel values. This is how computers see images. But like this, it doesn't maen much to us. Let's visualize this sample.\n",
        "\n",
        "Convert the pixel values into an image by using the imshow() function of the Matplotlib library.\n",
        "\n",
        "Print the shape of the image using shape."
      ],
      "metadata": {
        "id": "kPnbc7H2b0if"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the .imshow() function and show the plot\n",
        "plt.imshow(X_test[789])\n",
        "plt.show()\n",
        "# Print the shape of the sample image\n",
        "print(X_test[789].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "bvn23gqIbxUX",
        "outputId": "4638dcfa-ed40-44ed-abbf-4c0195b67ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing\n",
        "\n",
        "Great! With this knowledge we can adjust our dataset for further use.\n",
        "\n",
        "We need three datasets: train, validate, and test. We can separate 10000 images from the train dataset and use it as the validation dataset.\n",
        "\n",
        "You can use list slicing for this."
      ],
      "metadata": {
        "id": "haB4K0nkcW28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the validation datasets and assign the last 1000 images of X_train and y_train\n",
        "X_val = X_train[40000:]\n",
        "y_val = y_train[40000:]\n",
        "\n",
        "# Create new train datasets and assign the first 40000 images of X_train and y_train\n",
        "X_train = X_train[:40000]\n",
        "y_train = y_train[:40000]\n"
      ],
      "metadata": {
        "id": "va9BlfZ-cu6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the number of samples in each dataset to see the final results.\n",
        "\n",
        "Use f-strings for this."
      ],
      "metadata": {
        "id": "5rZwxlo_e4pA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the lengths of the each dataset\n",
        "print(f\"X_train: {len(X_train)}\")\n",
        "print(f\"X_val: {len(X_val)}\")\n",
        "print(f\"X_test: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlQyQ42rc2lj",
        "outputId": "b34707e9-cd35-4a08-c926-8f4a74afba73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: 40000\n",
            "X_val: 10000\n",
            "X_test: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalization\n",
        "\n",
        "Since pixel values are between 0 and 255, dividing these values by 255 will scale each of them to values between 0 and 1. \n",
        "\n",
        "Divide each dataset by 255."
      ],
      "metadata": {
        "id": "I-3KmOZpfF1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide each dataset by 255\n",
        "X_train = X_train/255\n",
        "X_val = X_train/255\n",
        "X_test = X_test/255"
      ],
      "metadata": {
        "id": "LPWwPmqtgylM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constructing the neural network\n",
        "\n",
        "That was it for the preprocessing of the data!\n",
        "\n",
        "Now we can create out model. First things first, we start by creating a model object using Sequential API of Keras.\n",
        "\n",
        "Use tf.keras.Sequential() to create a model object."
      ],
      "metadata": {
        "id": "msRRQ9Evg13a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model object\n",
        "model = tf.keras.Sequential()"
      ],
      "metadata": {
        "id": "7Ot4t1QKhLbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature extraction layers\n",
        "\n",
        "For the first two layers, we add a convolution and max pooling layer.\n",
        "\n",
        "Use tf.keras.layers.Conv2D() and tf.keras.layers.MaxPooling2D() to create the layers.\n",
        "\n",
        "Use .add() method of the object to add the layer."
      ],
      "metadata": {
        "id": "DYE8f5Z5hRJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a concolution and max pooling layer\n",
        "model.add(tf.keras.layers.Conv2D(32, \n",
        "                                 kernel_size = (3, 3), \n",
        "                                 strides = (1, 1), \n",
        "                                 padding = \"same\", \n",
        "                                 activation = \"relu\", \n",
        "                                 input_shape = (32, 32, 3)))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPooling2D((2,2)))"
      ],
      "metadata": {
        "id": "68xvnJOIhlFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we add more layers. One concolution, one max pooling, and one convolution layer again.\n",
        "\n",
        "Use tf.keras.layers.Conv2D() and tf.keras.layers.MaxPooling2D() to create the layers.\n",
        "\n",
        "Use .add() method of the object to add the layer."
      ],
      "metadata": {
        "id": "22dlXUUHidb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add more convolution and max pooling layers\n",
        "model.add(tf.keras.layers.Conv2D(64, \n",
        "                                 kernel_size = (3, 3), \n",
        "                                 strides = (1, 1), \n",
        "                                 padding = \"same\", \n",
        "                                 activation = \"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(64, \n",
        "                                 kernel_size = (3, 3), \n",
        "                                 strides = (1, 1), \n",
        "                                 padding = \"same\", \n",
        "                                 activation = \"relu\"))"
      ],
      "metadata": {
        "id": "a1jTi5I9iN3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flatten \n",
        "\n",
        "To connect the 2D convolution and 1D dense layers we have to \"flatten\" the convolution layer.\n",
        "\n",
        "Use tf.keras.layers.Flatten() to flatten the layers.\n",
        "\n",
        "Use .add() method of the object to add the layer."
      ],
      "metadata": {
        "id": "_DfBVaF1liZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the convolution layer\n",
        "model.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "jQcUcyVLmVtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification Layers\n",
        "\n",
        "Now that we have the features extracted, we can move on to the classification part. We add two dense layers each with 64 nodes, 0.5 dropout and ReLU activation functions.\n",
        "\n",
        "Use tf.keras.layers.Dense() to create the layers.\n",
        "\n",
        "Use .add() method of the object to add the layer."
      ],
      "metadata": {
        "id": "6JtKUnIgmWrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the dense layer and dropout layer\n",
        "model.add(tf.keras.layers.Dense(64, activation = \"relu\"))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "# Add the dense layer and dropout layer\n",
        "model.add(tf.keras.layers.Dense(64, activation = \"relu\"))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n"
      ],
      "metadata": {
        "id": "5w8qEeQMoEcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output Layer\n",
        "\n",
        "As the last part of our neural network, we add the output layer. The number of nodes will be equal to the number of target classes which is 10 in our case. We'll use the softmax activation function in the output layer.\n",
        "\n",
        "Use tf.keras.layers.Dense() to create the layer.\n",
        "\n",
        "Use .add() method of the object to add the layer."
      ],
      "metadata": {
        "id": "DkJfWop-pbq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the output layer\n",
        "model.add(tf.keras.layers.Dense(10, activation = \"softmax\"))"
      ],
      "metadata": {
        "id": "gpBdhV0lp3Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer\n",
        "\n",
        "Now we have the structure of our model. To configure the model for training we'll use the .compile() method. Inside the compile method we have to define the following:\n",
        "\n",
        "* \"Adam\" for optimizer\n",
        "\n",
        "* \"Sparse Categorical Crossentropy\" for the loss function\n",
        "\n",
        "Construct the model with the .compile() method."
      ],
      "metadata": {
        "id": "Xuf7XhzXqFYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer = \"adam\", \n",
        "              loss = \"sparse_categorical_crossentropy\", \n",
        "              metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "5_979XkYqh2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Model\n",
        "\n",
        "It's time to train the model. We'll give the X_train and y_train datasets as the first two arguments. These will be used for training. And with the validation_data parameter we'll give the X_val and y_val as a tuple.\n",
        "\n",
        "Use .fit() method of the model object for the training."
      ],
      "metadata": {
        "id": "kyYN19LCqk5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model for 50 epochs\n",
        "results = model.fit(X_train, y_train, \n",
        "                    batch_size = 128, \n",
        "                    epochs = 50, \n",
        "                    validation_data = (X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "jiTf3vTFrXsO",
        "outputId": "8c0c13ea-1659-426f-8538-e3f62977d030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "313/313 [==============================] - ETA: 0s - loss: 2.0269 - accuracy: 0.2218"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1ca608dcd8f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     validation_data = (X_val, y_val))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1652\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 40000\n  y sizes: 10000\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the Result\n",
        "\n",
        "After the model is trained, we can create a graph to visualize the change of loss over time. Results are held in:\n",
        "\n",
        "* results.history[\"loss\"]\n",
        "\n",
        "* results.history[\"val_loss\"]\n",
        "\n",
        "Use plt.show() to display the graph."
      ],
      "metadata": {
        "id": "R5lDBN6wr2bV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training loss\n",
        "plt.plot(results.history[\"loss\"], label = \"loss\")\n",
        "\n",
        "# Plot the validation loss\n",
        "plt.plot(results.history[\"val_score\"], label = \"val_score\")\n",
        "\n",
        "# Name the x and y axises\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "# Put legend table\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "069SUUT0sSOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now do the same thing for accuracy.\n",
        "\n",
        "Accuracy scores can be found in:\n",
        "\n",
        "  * results.history[\"accuracy\"]\n",
        "\n",
        "  * results.history[\"val_accuracy\"]"
      ],
      "metadata": {
        "id": "zGd_KMLTBaTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training accuracy\n",
        "plt.plot(results.history[\"accuracy\"], label = \"accuracy\")\n",
        "\n",
        "# Plot the validation accuracy\n",
        "plt.plot(results.history[\"val_accuracy\"], label = [\"val_accuracy\"])\n",
        "\n",
        "# Name the x and y axises\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "# Put legend table\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PFNi1ZvkvNqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance evaluation\n",
        "\n",
        "Let's use the dataset we created to evaluate the performance of the model.\n",
        "\n",
        "Use test_on_batch() method with test dataset as parameter."
      ],
      "metadata": {
        "id": "FSPejw_cCRBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "bU3qWLONCkgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try a prediction\n",
        "\n",
        "Next, we take the sample we selected at the beginning and make a prediction on it.\n",
        "\n",
        "Reshape the image to (1, 32, 32, 3)\n",
        "\n",
        "Use the .prediction() method of the model object."
      ],
      "metadata": {
        "id": "7qx-TyKACq_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction on the reshaped sample\n",
        "prediction_result = model.predict(X_test[789].reshape(1, 32, 32, 3))\n",
        "\n",
        "# Print the prediction result\n",
        "prediction_result\n"
      ],
      "metadata": {
        "id": "m60ZG5jSC8AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we find the predicted class and prediction probability and print the results.\n",
        "\n",
        "Use .argmax() to find the class.\n",
        "\n",
        "Use .max() to find the probability."
      ],
      "metadata": {
        "id": "AlRcEyhNDD4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the predicted class\n",
        "predicted_class = prediction_result.argmax()\n",
        "\n",
        "# Find the prediction probability\n",
        "predicted_probability = prediction_result.max()\n",
        "\n",
        "# Print the results\n",
        "print(f\"This image belongs to class {predicted_class} with {predicted_probability} probability %\")"
      ],
      "metadata": {
        "id": "zgIGi2d2E1_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AI9061 Recurrent Neural Networks\n",
        "\n",
        "Hello and welcome back! Before we begin, I would like to ask you a question this time. Let’s say, you ate pizza for lunch, would you like to eat pizza for dinner as well? Most likely you would not, right? So, your decision is influenced by an event that has happened before. If we want our deep learning model to suggest what to eat for dinner today, we need to provide the information regarding what we had for lunch. Similarly, financial markets use information from the past, to predict future stock value. Brokers see the market trends if they are rising or falling, before they make any decision. This problem can be formulated, and a deep learning model can be used to predict the stock prices, using the information from the past. In this video, we will learn how to train deep learning models to understand temporal information. We will discuss Recurrent Neural Networks, or RNNs. One of the most exciting deep learning models.\n",
        "\n",
        " \n",
        "\n",
        "We understand the importance of temporal information. Now, it is time to teach computers how to make use of information from the past. One of the decades-old ways of solving this problem is a recurrent neural network. A traditional recurrent neural network has an input layer, a hidden state, and an output layer. The hidden state is different from the hidden layer of an Artificial Neural Network. It represents information from previous time steps. RNNs are designed to process the sequential data. Sequential data is the one in which each data point is connected to the previous, and/or the future datapoint. The hidden state is responsible for summarizing and storing information from the past. Since the RNN model takes the data points from the past, it has to track the time. A timestep refers to the number of inputs that has been passed to the network as a sequence. A timestep of 10 means, the previous 9 data points and the current point will be used to predict the output. A typical RNN model takes the current input x at time step t, and “the hidden state a” of time step t-1. The RNN model returns the output y of time step t and “the hidden state a” of time step t. Because the hidden state passed through the network, the timestep of the hidden state is updated to t. Let’s check these steps together. The model takes input and multiplies it by its associated weight – it takes the hidden state and multiplies it by its associated weights – adds these two products and a bias – and applies the activation function. The result of these steps, will give us the input to the output layer and also the hidden state for the next time step. Then, the same steps will be implemented for the next input. This is how we can use RNNs to take into account the historical information. You can see that if we increase the length of the input sequence, the model size does not change, because it has one hidden state that gets updated over time.\n",
        "\n",
        " \n",
        "\n",
        "Now, let’s see different types of RNNs and their applications. One-to-many. We can input an image, and it can generate a sequence of words (a sentence) that is the caption of the image. Many-to-one. Consider the example from financial markets where the previous information sequence is passed as input and the model predicts the future price. Many-to-many, where the length of the input and output is the same. For example, object tracking in a video. In this case, video frames are the input and the location of the object in each frame is the output. There can also be many-to-many RNNs with different lengths of input and output. You probably have used Google translate before. The length of the sentence in English, might not be the same as the translated French sentence. We learned, why we may want to use temporal information in our models and how RNNs can do that to generate an output or a sequence of output. We discussed different architectures of the RNNs and their applications. However, like everything else, RNNs are not perfect. RNNs are slow. Sometimes very slow. Plus, it is difficult for the hidden state to represent the information from long ago, and thus, it has difficulty accessing information from the far past. On top of that, RNNs are sometimes very hard to train. The backpropagation is done at each point in time. RNN can do great things, but training an RNN is a tricky task. In the next video, we will talk about some tips and tricks, to train an RNN. Stay tuned."
      ],
      "metadata": {
        "id": "VhkUJtnUGoGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AI9062 Training Recurrent Neural Networks\n",
        "\n",
        "Welcome Back! In the last video, we learned how recurrent neural networks can account for information from the past, when computing the output. We also discussed some exciting applications of RNNs. But training an RNN is not a simple task. In this video, we will learn how to train a recurrent neural network, and address the problems associated with the training.\n",
        "\n",
        " \n",
        "\n",
        "The first step of training is to compute the loss. In the case of a recurrent neural network, the final loss, is the sum of the loss at every time step. Backpropagation is done at each point in time. It means that, if the input sequence of length10 is fed to the network, the backpropagation will calculate the gradient from the first time step, to the last time step. And then all these parameters will be updated accordingly. If the sequences are long, the hidden state has the burden of representing the information from all the previous time steps. This means that, the computation from the first time step might be impacting the computation on the output on the 78 time step, for example. We use the same weights for hidden states throughout all the time steps. And if we compute the gradient, the gradient at the first step has weight W, with the power of 78. This might cause the gradients to explode, which means the gradient goes to infinity. And the RNN might not be able to learn, because the gradient descent will not be meaningful and the training will be very unstable.\n",
        "\n",
        " \n",
        "\n",
        "For example, let’s say you want to train a text prediction model that takes words as input as you type them, and it predicts the next word that you might type. If you face the exploding gradient problem, your loss will explode and your training will not be successful. To cope with the exploding gradient problem, a technique called gradient clipping can be used during backpropagation. Here we cap the maximum value of the gradient. If the gradient exceeds a certain maximum value threshold, we assign the capping value to it. This way no number will reach infinity. You may also face a problem of vanishing gradients, where the gradients become zero or very close to zero. This usually happens when RNNs are not able to capture long term dependencies in the input sequence. If you encounter the vanishing gradient problem in your text prediction model, the whole context of the text might be missed, because your predictions will be based just on the last few words. To solve the vanishing gradients problem, the architecture of the simple RNN unit has to be modified and we need to introduce two modified versions of RNNs. The 2 most commonly used types of RNNs to address these issues are Gated Recurrent Units, GRUs, and Long Short-Term Memory Units, LSTMs. GRUs and LSTMs deal with the vanishing gradient problem of traditional RNNs. Here is how.\n",
        "\n",
        " \n",
        "\n",
        "The GRU has two gates, a reset gate and an update gate. Gates are nothing but neural networks, each gate has its own weights and biases. In the GRU, we refer to the hidden state as the candidate cell. And this candidate cell will also serve as the output. The update gate decides if the cell state should be updated with the candidate state, the current activation value, or not. The reset gate is used to decide whether the previous cell state is important or not. Sometimes the reset gate is not used in a simple GRU. The cell state for the next time step is dependent on the update gate. It may update the cell state by adding some useful information and by removing some information that is not required. Let’s see how this architecture works with an example. We can use the text prediction model we mentioned. Imagine you are typing the sentence and the model needs to predict the next word. Useless or redundant information is dropped and only useful information is carried to the next time step by the candidate cell. This does not let the candidate cell to be overwhelmed with information and thus, it can simply solve the vanishing gradient problem. Now that you are aware of RNN and GRU, let’s quickly learn how LSTM works. Similar to GRUs in many ways, LSTMs are used to address the issue of disappearing gradients. In LSTMs there are three gates: Input gate, forget gate and output gate. LSTMs have cell state as well as hidden state.\n",
        "\n",
        " \n",
        "\n",
        "The input gate decides what relevant information can be added from the current step. The forget gate controls what is kept vs forgotten, from the previous cell state. In layman’s terms, it will decide how much information from the previous state should be kept and forget the rest. The output gate controls which parts of the cell are output to the hidden state. It will determine what the next hidden state will be. Like GRUs, LSTMs only keep the useful information and tend to discard what is unnecessary. This solves our vanishing gradients problem. The key difference between GRUs and LSTMs is that, GRUs have two gates that are reset and update, while LSTMs have three gates that are input, output, and forget. GRUs are less complex than LSTMs because they have fewer gates. If the dataset is small then GRUs are preferred, otherwise LSTMs for larger datasets. This was a tough lesson but you made it. In this video, we learned how RNNs are trained. What are the major issues RNNs run into, and what causes exploding and vanishing gradient problems? We learned how to solve exploding gradient problems with the gradient clipping technique and vanishing gradient problems with GRU and LSTM. With this video, your lesson on RNN is completed. Now it is time to practice with some practical examples. See you there."
      ],
      "metadata": {
        "id": "WnDpEqaGLToz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build a Recurrent Neural Network\n",
        "\n",
        "Welcome to the last guided project of this course! In this project, we will build a recurrent neural network for sentiment classification. In sentiment classification, we identify if a text includes positive, negative or neutral opinions and label them. This method can be used to understand how people feel about a product or service based on comments they leave. For this exercise, we’ll explore how people feel about movies. We will use the “IMDB Movie Review Dataset”. This dataset provides 50000 highly polarized movie reviews categorized as positive or negative, so we have a binary classification problem. We’ll tackle this problem by creating a LSTM neural network. As always we’ll start with preprocessing the data, then we’ll construct and train our model and finally evaluate and fine-tune it.\n",
        "\n",
        " \n",
        "\n",
        "Let’s start by importing the required libraries. We’ll use Tensorflow, NumPy and Matplotlib. Next, we need to get our data. For this, we download the IMDB dataset which is included in Keras and already divided into train and test sets. We can directly assign it to the corresponding variables. While downloading this dataset from TensorFlow, there is another parameter we can set; num_words. If we specify the number ‘n’ for this parameter, only the most frequent ‘n’ words will be downloaded, otherwise all words will be kept. We want to include the most frequently used 10000 words. Of course, we can select a higher number but doing so will require a lot of memory. Let’s also have a look inside our dataset. We print X_train[0] and check the data we have. We can see that we have an array of lists where each list corresponds to a different movie review. Inside these lists we see a lot of numbers. The actual movie reviews consisted of words, but because we can’t do mathematical operations on string data, these words had to be converted to numbers. Luckily, this was already done for us; each word is mapped to a specific number in the dataset. For example the word “good” is mapped to the number 49, the word “bad” is mapped to the number 75. If this wasn’t done by default, we could easily create a script where we assign numbers to words. Now let’s print the lengths of the X_train and X_test variables to see the number of samples and the distribution between the datasets. There are 25000 reviews, or samples, in each set. This means a 50-50 split. Remember that we need three datasets for deep learning training: train, validation and test datasets with a split ratio of 80-10-10. First let’s combine the existing train and test sets to create one big dataset. After that we’ll split it. To do that we concatenate both “samples” lists and “labels” lists. Now we have two datasets of samples and labels.\n",
        "\n",
        " \n",
        "\n",
        "Before dividing these datasets, we can already do some preprocessing operations, so we won’t have to do this three times for each dataset later. What we’ll be doing now is called ‘padding’. Since the movie reviews are of different lengths, we can add some zeros to the beginning of the reviews, just like we did on CNNs, so that all samples will be at the same length. The max_len parameter here will resize all reviews to 1024words. Any samples below this length will get extra zeros and any reviews above this length will be trimmed. If we hadn’t specified any number for the max_len parameter here, all sequences would have been padded to the length of the longest individual sequence. In our case this would significantly increase the training time. By the way, when you get to the hyperparameter tuning part later, you can try different maximum lengths and see if you can find the best performing one. Padding is done! Now we can split the samples and labels to train, validation and test datasets with a 80-10-10 ratio. We simply use the indices to define them. To be safe, we print the lengths to check if everything worked out. Great! Our dataset is ready to use!\n",
        "\n",
        " \n",
        "\n",
        "We can start to build our model. First, we create a model object. The first layer we will add is a so-called “embedding layer”. Word embedding is a method to represent words or text in a numerical way. It allows us to encode meaning to words by representing them in the form of vectors in a vector space. Here, words that are expected to have a similar meaning are closer to each other. In our case, we will translate 10000 words we have to a 256-dimensional plane. Remember that the input layer is the data we have. Layer we are adding here is not the input layer but the layer after that. By using the input_dim parameter, we specify that the input layer includes 10000 words as inputs, this means that we add the input layer without adding another layer separately, but with using the input_dim parameter. After embedding, we add dropout. Next, we’ll add an LSTM gate, in other words, an LSTM layer. We specify the number of nodes. Now we add dropout to the LSTM layer. And a dense layer with dropout. And lastly, we add an output layer. Remember that in multi-class classification problems the number of nodes in the output layer would be equal to the number of classes and we would use softmax activation function. In this project, we are trying to make a binary classification. So the output layer will have only one node and a sigmoid activation function. With the sigmoid activation function, the network will output a value between 0 and 1. So if the value is below 0.5 it will be class 0 which means the class of negative reviews and if above,the class will be 1 for positive reviews.\n",
        "\n",
        " \n",
        "\n",
        "Let’s build the model using the compile method. As always we’ll use the adam optimizer. This time we’ll be using the “Binary Cross Entropy” loss function because this is a binary classification problem. Remember that if we had more than two classes we would have to use “Sparse Categorical Cross Entropy”. We are almost there! Now we train it for 5 epochs because training this model takes so much time since there are many parameters the model has to adjust. You try different numbers of epochs to find the best performing model. Great, our model is done! Let’s see how well it performs. As usual, we can create graphs to review the change of the loss and accuracy. Let’s visualize the change of the loss first. And then the change of the accuracy.\n",
        "\n",
        " \n",
        "\n",
        "We can see from both graphs that there is no overfitting. The lines in both graphs converge in a good way. But we only trained this model for 5 epochs. Would training for longer lead to a better model or just overfitting? You’ll figure out that in the hyperparameter tuning part. Let’s evaluate the model using X_test and y_test datasets. The loss value is 0.24 and the accuracy is 0.90. Even though the accuracy is relatively high, maybe we can improve its performance with hyperparameter tuning. Now let’s pick a single sample randomly and see if the model predicts correctly. The predict method works on batches of data but since we are predicting only on one sample, we have to reshape the sample. We are going to reshape the review to 1 by 1024. Remember that we padded each review to have the length of 1024. Then we print the prediction result and the label that the sample has in the dataset to compare them. Our model output 0.2. Remember that if the output is smaller than 0.5 we say it belongs to 0. And since the result is very close to zero we can say that model predicted this review as a “negative” one. The label is also zero so we can conclude that the model made a correct prediction.\n",
        "\n",
        " \n",
        "\n",
        "It’s time for fine-tuning the model. But before that, remember the parameter we set at the beginning? You can play with the num_words parameter of the “load_dataset” function and the maxlen parameter of the “pad_sequences” function to see how those affect the model training and performance. After doing that, change the following parameters: number of units on the LSTM layer, dropout rate, recurrent dropout rate, optimizer and try to find the best performing model.\n",
        "\n",
        " \n",
        "\n",
        "Now we know how basic sentiment analysis works. In this project we learned how to create a RNN using TensorFlow, how to do embedding and padding and how to use LSTM in a real life problem. We also saw how binary and multi-class classification differentiate in practice. This means we have taken our first step towards one of the major artificial intelligence topics: natural language processing.\n",
        "\n",
        " \n",
        "\n",
        "Congrats! You made it to the end of the last guided project. As we always say, it is your turn to practice more now!"
      ],
      "metadata": {
        "id": "AOEbc2D0vaaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AI9071 Build a Recurrent Neural Network\n",
        "\n",
        "Welcome to the last guided project of this course! In this project, we will build a recurrent neural network for sentiment classification. In sentiment classification, we identify if a text includes positive, negative or neutral opinions and label them. This method can be used to understand how people feel about a product or service based on comments they leave. For this exercise, we’ll explore how people feel about movies. We will use the “IMDB Movie Review Dataset”. This dataset provides 50000 highly polarized movie reviews categorized as positive or negative, so we have a binary classification problem. We’ll tackle this problem by creating a LSTM neural network. As always we’ll start with preprocessing the data, then we’ll construct and train our model and finally evaluate and fine-tune it.\n",
        "\n",
        " \n",
        "\n",
        "Let’s start by importing the required libraries. We’ll use Tensorflow, NumPy and Matplotlib. Next, we need to get our data. For this, we download the IMDB dataset which is included in Keras and already divided into train and test sets. We can directly assign it to the corresponding variables. While downloading this dataset from TensorFlow, there is another parameter we can set; num_words. If we specify the number ‘n’ for this parameter, only the most frequent ‘n’ words will be downloaded, otherwise all words will be kept. We want to include the most frequently used 10000 words. Of course, we can select a higher number but doing so will require a lot of memory. Let’s also have a look inside our dataset. We print X_train[0] and check the data we have. We can see that we have an array of lists where each list corresponds to a different movie review. Inside these lists we see a lot of numbers. The actual movie reviews consisted of words, but because we can’t do mathematical operations on string data, these words had to be converted to numbers. Luckily, this was already done for us; each word is mapped to a specific number in the dataset. For example the word “good” is mapped to the number 49, the word “bad” is mapped to the number 75. If this wasn’t done by default, we could easily create a script where we assign numbers to words. Now let’s print the lengths of the X_train and X_test variables to see the number of samples and the distribution between the datasets. There are 25000 reviews, or samples, in each set. This means a 50-50 split. Remember that we need three datasets for deep learning training: train, validation and test datasets with a split ratio of 80-10-10. First let’s combine the existing train and test sets to create one big dataset. After that we’ll split it. To do that we concatenate both “samples” lists and “labels” lists. Now we have two datasets of samples and labels.\n",
        "\n",
        " \n",
        "\n",
        "Before dividing these datasets, we can already do some preprocessing operations, so we won’t have to do this three times for each dataset later. What we’ll be doing now is called ‘padding’. Since the movie reviews are of different lengths, we can add some zeros to the beginning of the reviews, just like we did on CNNs, so that all samples will be at the same length. The max_len parameter here will resize all reviews to 1024words. Any samples below this length will get extra zeros and any reviews above this length will be trimmed. If we hadn’t specified any number for the max_len parameter here, all sequences would have been padded to the length of the longest individual sequence. In our case this would significantly increase the training time. By the way, when you get to the hyperparameter tuning part later, you can try different maximum lengths and see if you can find the best performing one. Padding is done! Now we can split the samples and labels to train, validation and test datasets with a 80-10-10 ratio. We simply use the indices to define them. To be safe, we print the lengths to check if everything worked out. Great! Our dataset is ready to use!\n",
        "\n",
        " \n",
        "\n",
        "We can start to build our model. First, we create a model object. The first layer we will add is a so-called “embedding layer”. Word embedding is a method to represent words or text in a numerical way. It allows us to encode meaning to words by representing them in the form of vectors in a vector space. Here, words that are expected to have a similar meaning are closer to each other. In our case, we will translate 10000 words we have to a 256-dimensional plane. Remember that the input layer is the data we have. Layer we are adding here is not the input layer but the layer after that. By using the input_dim parameter, we specify that the input layer includes 10000 words as inputs, this means that we add the input layer without adding another layer separately, but with using the input_dim parameter. After embedding, we add dropout. Next, we’ll add an LSTM gate, in other words, an LSTM layer. We specify the number of nodes. Now we add dropout to the LSTM layer. And a dense layer with dropout. And lastly, we add an output layer. Remember that in multi-class classification problems the number of nodes in the output layer would be equal to the number of classes and we would use softmax activation function. In this project, we are trying to make a binary classification. So the output layer will have only one node and a sigmoid activation function. With the sigmoid activation function, the network will output a value between 0 and 1. So if the value is below 0.5 it will be class 0 which means the class of negative reviews and if above,the class will be 1 for positive reviews.\n",
        "\n",
        " \n",
        "\n",
        "Let’s build the model using the compile method. As always we’ll use the adam optimizer. This time we’ll be using the “Binary Cross Entropy” loss function because this is a binary classification problem. Remember that if we had more than two classes we would have to use “Sparse Categorical Cross Entropy”. We are almost there! Now we train it for 5 epochs because training this model takes so much time since there are many parameters the model has to adjust. You try different numbers of epochs to find the best performing model. Great, our model is done! Let’s see how well it performs. As usual, we can create graphs to review the change of the loss and accuracy. Let’s visualize the change of the loss first. And then the change of the accuracy.\n",
        "\n",
        " \n",
        "\n",
        "We can see from both graphs that there is no overfitting. The lines in both graphs converge in a good way. But we only trained this model for 5 epochs. Would training for longer lead to a better model or just overfitting? You’ll figure out that in the hyperparameter tuning part. Let’s evaluate the model using X_test and y_test datasets. The loss value is 0.24 and the accuracy is 0.90. Even though the accuracy is relatively high, maybe we can improve its performance with hyperparameter tuning. Now let’s pick a single sample randomly and see if the model predicts correctly. The predict method works on batches of data but since we are predicting only on one sample, we have to reshape the sample. We are going to reshape the review to 1 by 1024. Remember that we padded each review to have the length of 1024. Then we print the prediction result and the label that the sample has in the dataset to compare them. Our model output 0.2. Remember that if the output is smaller than 0.5 we say it belongs to 0. And since the result is very close to zero we can say that model predicted this review as a “negative” one. The label is also zero so we can conclude that the model made a correct prediction.\n",
        "\n",
        " \n",
        "\n",
        "It’s time for fine-tuning the model. But before that, remember the parameter we set at the beginning? You can play with the num_words parameter of the “load_dataset” function and the maxlen parameter of the “pad_sequences” function to see how those affect the model training and performance. After doing that, change the following parameters: number of units on the LSTM layer, dropout rate, recurrent dropout rate, optimizer and try to find the best performing model.\n",
        "\n",
        " \n",
        "\n",
        "Now we know how basic sentiment analysis works. In this project we learned how to create a RNN using TensorFlow, how to do embedding and padding and how to use LSTM in a real life problem. We also saw how binary and multi-class classification differentiate in practice. This means we have taken our first step towards one of the major artificial intelligence topics: natural language processing.\n",
        "\n",
        " \n",
        "\n",
        "Congrats! You made it to the end of the last guided project. As we always say, it is your turn to practice more now!"
      ],
      "metadata": {
        "id": "xzfJavvHFdFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Recurrent Neural Network\n",
        "\n",
        "#### Sentiment Analysis\n",
        "\n",
        "In thist project, we will build a Long Short - Term Memory (LSTM) neural network to solve a binary sentiment analysis problem.\n",
        "\n",
        "For this we'll use the \"IMDB Movie Review Dataset\" available on Keras. It includes 50000 highly polarized movie reviews categorized as positive or negative."
      ],
      "metadata": {
        "id": "c6Ssdky0wO4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the Required Libraires\n",
        "\n",
        "We'll start with importing required libraries.\n",
        "\n",
        "Use the keyword \"import\"."
      ],
      "metadata": {
        "id": "POKTKzJiwwKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import NumPy and Matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "k-FOjk97Gw-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset\n",
        "\n",
        "Let's download the IMDB dataset which is included in Keras and assign it to the corresponding variables X_train, y_train, X_test, y_test. We want to include the most frequently used 10000 words so we specify 10000 for the num_words parameter.\n",
        "\n",
        "* Use the datasets.imdb.load_data() function of the Keras"
      ],
      "metadata": {
        "id": "h_ji8yHhxOCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the IMDB dataset included in Keras\n",
        "# Set the parameter num_words to 10000\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.imdb.load_data(num_words = 10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzAD5dgtx8y5",
        "outputId": "e3c69322-0feb-40fe-ffc5-45ba208187cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we move on, we can print a single sample to see what the data looks like.\n",
        "\n",
        "* Use the print() function for this."
      ],
      "metadata": {
        "id": "xVbIQq7jyTTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a sample\n",
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tVR-6WJyQGt",
        "outputId": "da610039-f153-486e-f003-7e13b64b0d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we print the number of samples in the X_train and X_test datasets to see how the dataset is distributed.\n",
        "\n",
        "* Use f-strings for this."
      ],
      "metadata": {
        "id": "VZ3ZCZFmy9Gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of samples\n",
        "print(f\"X_train: {len(X_train)}\")\n",
        "print(f\"X_test: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAKPH3V-1OJV",
        "outputId": "4687e7d1-caa5-45ba-8bf5-66bc2c39084c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: 25000\n",
            "X_test: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing\n",
        "\n",
        "Concatenate\n",
        "\n",
        "To split the dataset with 80-10-10 ratio we'll first concatenate train and test datasets to create one big dataset.\n",
        "\n",
        "* Use contenate() function of the NumPy library for this."
      ],
      "metadata": {
        "id": "Oa669rUe1Xx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate X_train and X_test and assing it to a variable X\n",
        "X = np.concatenate((X_train, X_test), axis = 0)   \n",
        "\n",
        "# Concatenate y_train and y_test and assing it to a variable y\n",
        "y = np.concatenate((y_train, y_test), axis = 0)\n"
      ],
      "metadata": {
        "id": "dUlqBhwG1rjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding\n",
        "\n",
        "Since all reviews are at different lengths, we'll use padding to make all of them same length.\n",
        "\n",
        "* Use preprocessing.sequence.pad_sequences() function for this."
      ],
      "metadata": {
        "id": "id92fWmD23Hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad all reviews in the X dataset to the length maxlen=1024\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=1024)"
      ],
      "metadata": {
        "id": "StRShZ162lai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting\n",
        "\n",
        "Now, split X and y into train, validation and test dataset and assign those to corresponding values.\n",
        "\n",
        "* You can use list slicing methods for this.\n",
        "\n",
        "* For this dataset, a 80-10-10 split corresponds to 40000 - 10000 - 10000 number of samples relatively."
      ],
      "metadata": {
        "id": "DtCkvHDn3a8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training datasets\n",
        "X_train = X[:40000]\n",
        "y_train = y[:40000]\n",
        "\n",
        "# Create the validation datasets\n",
        "X_val = X[40000:45000]\n",
        "y_val = y[40000:45000]\n",
        "\n",
        "# Create the test datasets\n",
        "X_test = X[45000:50000]\n",
        "y_test = y[45000:50000]\n"
      ],
      "metadata": {
        "id": "I-iIXN1E3Zd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check if that worked out, print the number of samples in each dataset again.\n",
        "\n",
        "* Use f-strings for this."
      ],
      "metadata": {
        "id": "zgsPx6M14OX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of samples\n",
        "print(f\"X_train: {len(X_train)}\")\n",
        "print(f\"y_train: {len(y_train)}\")\n",
        "print(f\"X_val: {len(X_val)}\")\n",
        "print(f\"y_val: {len(y_val)}\")\n",
        "print(f\"X_test: {len(X_test)}\")\n",
        "print(f\"y_test: {len(y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spjxpoVz4hjn",
        "outputId": "b69119f4-2356-4424-83c8-de4fa08affd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: 40000\n",
            "y_train: 40000\n",
            "X_val: 5000\n",
            "y_val: 5000\n",
            "X_test: 5000\n",
            "y_test: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constructing the Neural Network\n",
        "\n",
        "That was it for the preprocessing of the data!\n",
        "\n",
        "Now we can create our model. First things first, we start by creating a model object using Sequential API of Keras.\n",
        "\n",
        "* Use tf.keras.Sequential() to create a model object."
      ],
      "metadata": {
        "id": "e3mJKk4T5fvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()"
      ],
      "metadata": {
        "id": "2xifGO554jev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding Layer\n",
        "\n",
        "For the first layer, we add an embedding layer.\n",
        "\n",
        "* Use tf.keras.layers.Embedding() for the embedding layer.\n",
        "\n",
        "* Use .add() method of the object to add the layer."
      ],
      "metadata": {
        "id": "1P3-Wf3g6D7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an embedding layer and a dropout.\n",
        "model.add(tf.keras.layers.Embedding(input_dim = 10000, output_dim = 256))\n",
        "model.add(tf.keras.layers.Dropout(0.7))"
      ],
      "metadata": {
        "id": "rrDYFCEz6aPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we add a LSTM layer and a dense layer; each with a dropout.\n",
        "\n",
        "* Use tf.keras.layers.LSTM() and tf.keras.layers.Dense() to create the layers.\n",
        "\n",
        "* Use .add() method of the object to add the layer."
      ],
      "metadata": {
        "id": "q0OLBlOp6eza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a LSTM layer with dropout\n",
        "model.add(tf.keras.layers.LSTM(256))\n",
        "model.add(tf.keras.layers.Dropout(0.7))\n",
        "\n",
        "# Add a Dense layer with dropout\n",
        "model.add(tf.keras.layers.Dense(128, activation = \"relu\"))\n",
        "model.add(tf.keras.layers.Dropout(0.7))\n"
      ],
      "metadata": {
        "id": "vLQA4ccH6x0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output Layer\n",
        "\n",
        "As the last part of out neural network, we add the output layer. The number of nodes will be one since we are making binary classification. We'll use the sigmoid activation function in the output layer.\n",
        "\n",
        "* Use tf.keras.layers.Dense() to create the layer.\n",
        "\n",
        "* Use .add() method of the object to add the layer."
      ],
      "metadata": {
        "id": "Osw-BSAG8NRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the output layer\n",
        "model.add(tf.keras.layers.Dense(1, activation = \"sigmoid\"))"
      ],
      "metadata": {
        "id": "mvFVWEJc8IXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer\n",
        "\n",
        "Now we have the structure of our model. To configure the model for training we'll use the .compile() method. Inside the compile method we have to define the following:\n",
        "\n",
        "  * \"Adam\" for optimizer\n",
        "\n",
        "  * \"Binary Crossentropy\" for the loss function\n",
        "\n",
        "* Construct the model with the .compile() method."
      ],
      "metadata": {
        "id": "Mb1U5aLU9R-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "HuxBKfvW9QuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Model\n",
        "\n",
        "It's time to train the model. We'll give the X_train and y_train datasets as the first two arguments. These will be used for training. And with the validation data parameter we'll give the X_val and y_val as a tuple.\n",
        "\n",
        "* Use .fit() method of the model object for the training."
      ],
      "metadata": {
        "id": "CaZzJ_EN953o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model for 5 epochs with batch size of 128\n",
        "results = model.fit(X_train, y_train, epochs = 5, validation_data = (X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVOf-_XX-Vtu",
        "outputId": "2d362db1-5979-4c68-b634-067d3a0072eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1250/1250 [==============================] - 101s 75ms/step - loss: 0.4954 - accuracy: 0.7600 - val_loss: 0.3882 - val_accuracy: 0.8312\n",
            "Epoch 2/5\n",
            "1250/1250 [==============================] - 86s 69ms/step - loss: 0.4142 - accuracy: 0.8181 - val_loss: 0.6084 - val_accuracy: 0.6974\n",
            "Epoch 3/5\n",
            "1250/1250 [==============================] - 87s 69ms/step - loss: 0.5875 - accuracy: 0.6735 - val_loss: 0.4376 - val_accuracy: 0.8106\n",
            "Epoch 4/5\n",
            "1250/1250 [==============================] - 88s 70ms/step - loss: 0.3920 - accuracy: 0.8287 - val_loss: 0.2414 - val_accuracy: 0.9024\n",
            "Epoch 5/5\n",
            "1250/1250 [==============================] - 87s 70ms/step - loss: 0.2363 - accuracy: 0.9140 - val_loss: 0.2337 - val_accuracy: 0.9072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the results\n",
        "\n",
        "After the model is trained, we can create a graph to visualize the change of loss over time. Results are held in:\n",
        "\n",
        "* results.history[\"loss\"]\n",
        "\n",
        "* results.history[\"val_loss\"]\n",
        "\n",
        "Use plt.show() to display the graph."
      ],
      "metadata": {
        "id": "rnH7xDCs-apQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training loss\n",
        "plt.plot(results.history[\"loss\"], label = \"Train\")\n",
        "\n",
        "# Plot the validation loss\n",
        "plt.plot(results.history[\"val_loss\"], label = \"Validation\")\n",
        "\n",
        "# Name the x and y axises\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "# Put legend table\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "kcCvGdMP_TIv",
        "outputId": "267e043e-3f3a-4ef7-913d-97ec56eb6bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, do the same thing for accuracy.\n",
        "\n",
        "* Accuracy scores can be found in:\n",
        "\n",
        "* results.history[\"accuracy\"]\n",
        "\n",
        "* results.history[\"val_accuracy\"]"
      ],
      "metadata": {
        "id": "wMYt2pXBBa-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training accuracy\n",
        "plt.plot(results.history[\"accuracy\"], label = \"Train\")\n",
        "\n",
        "# Plot the validation accuracy\n",
        "plt.plot(results.history[\"val_accuracy\"], label = \"Validation\")\n",
        "\n",
        "# Name the x and y axises\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "# Put legend table\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "iaQMzM0ICHIx",
        "outputId": "f8d51255-8fd6-4be5-c2e0-82bf4bf55470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance Evaluation\n",
        "\n",
        "Let's use the test dataset we created to evaluate the performance of the model.\n",
        "\n",
        "* Use test_on_batch() method with test dataset as parameter."
      ],
      "metadata": {
        "id": "jrMKdbF7C2By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWu7tOj9DQcZ",
        "outputId": "1906f353-d8c0-4043-d73e-3b7120ad0a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 4s 26ms/step - loss: 0.2292 - accuracy: 0.9040\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.22921982407569885, 0.9039999842643738]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try a Prediction\n",
        "\n",
        "Next, we take a sample and make a prediction on it.\n",
        "\n",
        "* Reshape the review to (1, 1024).\n",
        "\n",
        "* Use the .prediction() method of the model object."
      ],
      "metadata": {
        "id": "drxchXsVDTQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction on the reshaped sample\n",
        "prediction_result = model.predict(X_test[789].reshape(1, 1024))"
      ],
      "metadata": {
        "id": "440zcq2QDf0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Label: {y_test[789]} | Prediction: {prediction_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0W5IeKQFDNN",
        "outputId": "6dfeb417-e8dc-4987-c595-4d5f6fe9fb1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 0 | Prediction: [[0.05775834]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AI9081 Wrap Up\n",
        "\n",
        "Hello and welcome back! Congrats, we have come to the end of our course. Before we say goodbye, let’s quickly cover what we have learned so far, shall we? First, we introduced the structure of neural networks, how they are built of perceptrons, and their components: the input, hidden and output layers. And how the depth of one of these components, hidden layers, gave deep learning its name. After understanding its structure, we saw how information is transferred through a neural network model with forward propagation. Then we checked out how to improve an ANN model with training by changing its learnable parameters between each layer, so called weights and biases. We dove deeper into learnable parameter and hyperparameter terms. We learned about gradients and discovered how backpropagation is used to compute the gradients, in order to train a neural network model.\n",
        "\n",
        " \n",
        "\n",
        "In the second chapter, we talked about how machines perceive everything as numbers. So, it was time to understand how machines find their way between all the numbers. We learned what convolution is and how it is performed. We also introduced different types of convolutional kernels and how they extract features which deliver the needed spatial information. We discussed that while there are some ready to use predefined kernels, designed by incredible engineers, the kernel values can also be defined by the model. We looked at how feature extraction can happen without manually set filters. And with this knowledge in mind, we introduced the structure of one of the most crucial methods of deep learning: Convolutional Neural Networks.\n",
        "\n",
        " \n",
        "\n",
        "The last type of neural networks we introduced were Recurrent Neural Networks. We started with why we want to use temporal information in our models and explained how RNNs can do this for us. We learned how the hidden state represents information from previous time steps, different architectures of RNNs and their applications. We talked about the limitations of RNNs and of course how we can overcome them. The problem of exploding and vanishing gradients we may run into and how gradient clipping techniques, GRU and LSTM can help us solve these problems. And through all the way, we can proudly say that we also gained some pretty good hands-on experience with the projects we completed together.\n",
        "\n",
        " \n",
        "\n",
        "Remember, this is not the end, but only the beginning of your deep learning journey. Be ready to always discover more."
      ],
      "metadata": {
        "id": "j9ysY_paGmFR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLlqhc6-GrUH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}